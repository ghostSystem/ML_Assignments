{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification using Recurrent Neural Networks(RNN)\n",
    "In this homework, you will learn how to train a recurrent neural network for human action classification. RNN is designed handle sequential data. The network can incorporate both past history and current input. [This](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is a very good tutorial. You should read it before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Please make sure you have h5py and torchnet installed\n",
    "> pip install h5py\n",
    "\n",
    "> pip install git+https://github.com/pytorch/tnt.git@master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as DD\n",
    "import torchnet as tnt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('use cuda: %s'%(use_cuda))\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The data we are using is skeleton data, which indicates the 3D locations of body joints. In total, there are 25 body joints. It is collected by Kinect v2. To make it easier, each sequence have same number of frames. You need to classify 10 different actions. There are 2000 training sequences, 400 validation sequences, and 500 test sequences. Each sequence has 15 frames, each frame is a 75-dimension vector (3*25).\n",
    "\n",
    "For your convenience, we provide the dataloader for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(DD.Dataset):\n",
    "    # subset can be: 'train', 'val', 'test'\n",
    "    def __init__(self, data_path, subset='train'):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data_path = os.path.join(data_path, '%s_data.h5'%subset)\n",
    "        self.subset = subset\n",
    "\n",
    "        with h5py.File(self.data_path) as f:\n",
    "            self.data = np.array(f['data'])\n",
    "\n",
    "        if subset != 'test':\n",
    "            self.label_path = os.path.join(data_path, '%s_label.h5'%subset)\n",
    "            with h5py.File(self.label_path) as f:\n",
    "                self.label = np.array(f['label'])\n",
    "\n",
    "        self.num_sequences = self.data.shape[0]\n",
    "        self.seq_len = self.data.shape[1]\n",
    "        self.n_dim = self.data.shape[2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        seq = self.data[index]\n",
    "        if self.subset != 'test':\n",
    "            label = int(self.label[index])\n",
    "            sample = {'seq': seq, 'label': label}\n",
    "        else:\n",
    "            sample = {'seq': seq}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_sequences\n",
    "\n",
    "trSet = Dataset('./data', subset='train')\n",
    "valSet = Dataset('./data', subset='val')\n",
    "tstSet = Dataset('./data', subset='test')\n",
    "\n",
    "batch_size = 50\n",
    "trLD = DD.DataLoader(trSet, batch_size=batch_size,\n",
    "       sampler=DD.sampler.RandomSampler(trSet),\n",
    "       num_workers=2, pin_memory=False)\n",
    "valLD = DD.DataLoader(valSet, batch_size=batch_size,\n",
    "       sampler=DD.sampler.SequentialSampler(valSet),\n",
    "       num_workers=1, pin_memory=False)\n",
    "tstLD = DD.DataLoader(tstSet, batch_size=batch_size,\n",
    "       sampler=DD.sampler.SequentialSampler(tstSet),\n",
    "       num_workers=1, pin_memory=False)\n",
    "\n",
    "input_dim = trSet.n_dim\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Pytorch has implemented different types of recurrent layers for you. For this homework, you can use any type of RNNs as you want:\n",
    "> torch.nn.RNN()\n",
    "\n",
    "> torch.nn.LSTM()\n",
    "\n",
    "> torch.nn.GRU()\n",
    "\n",
    "You can check details for different types of recurrent layers here: [RNN](http://pytorch.org/docs/master/nn.html#torch.nn.RNN), [LSTM]( http://pytorch.org/docs/master/nn.html#torch.nn.LSTM), [GRU](http://pytorch.org/docs/master/nn.html#torch.nn.GRU)\n",
    "\n",
    "\n",
    "### Implement a specific model\n",
    "In this section, you need to implement a model for sequence classification. The model has following layers:\n",
    "* A linear layer that can map features of 75-dimension to 100-dimension.\n",
    "* 1 Layer LSTM layer with hidden size of 100\n",
    "* A linear layer that goes from 100 to num_class (10). \n",
    "\n",
    "An LSTM layer takes an input of size of (batch_size, seq_len, fea_dim) and outputs a variable of shape (batch_size, seq_len, hidden_size). In this homework, the classification score for a sequence is the classification score for the last step of rnn_outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        ############## 1st To Do (10 points) ##############\n",
    "        ###################################################\n",
    "        self.project_layer = nn.Linear(75, 100)\n",
    "        self.recurrent_layer = nn.LSTM(100, 100, 1)\n",
    "        self.classify_layer = nn.Linear(100, 10)\n",
    "        ###################################################\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer(input))\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "After you have the dataloader and model, you can start training the model. Define a SGD optimizer with learning rate of 1e-3, and a cross-entropy loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ 2nd To Do  (5 points)##################\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.3114,  Accuracy: 10.00\n",
      "val Epoch: 0  , Loss: 2.3088,  Accuracy: 9.25\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    "    return acc.value()[0]\n",
    "\n",
    "num_epochs = 1\n",
    "evaluate_every_epoch = 5\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        # Project Layer\n",
    "        self.project_layer = nn.Linear(75, 100)\n",
    "        # Recurrent Layer\n",
    "        self.recurrent_layer = nn.LSTM(100, 200, batch_first = True)\n",
    "        # Classify Layer\n",
    "        self.classify_layer = nn.Linear(200, 100)\n",
    "        self.classify_layer_2 = nn.Linear(100, 10)\n",
    "        # Regularization Layer\n",
    "        self.regularization = nn.Dropout(0.1)\n",
    "\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer(input))\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_2(rnn_outputs)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.3054,  Accuracy: 10.50\n",
      "val Epoch: 0  , Loss: 2.3079,  Accuracy: 9.75\n",
      "train Epoch: 1  , Loss: 2.3071,  Accuracy: 10.00\n",
      "val Epoch: 1  , Loss: 2.3075,  Accuracy: 10.00\n",
      "train Epoch: 2  , Loss: 2.3061,  Accuracy: 10.45\n",
      "val Epoch: 2  , Loss: 2.3072,  Accuracy: 9.50\n",
      "train Epoch: 3  , Loss: 2.3047,  Accuracy: 9.55\n",
      "val Epoch: 3  , Loss: 2.3068,  Accuracy: 10.50\n",
      "train Epoch: 4  , Loss: 2.3057,  Accuracy: 11.05\n",
      "val Epoch: 4  , Loss: 2.3064,  Accuracy: 9.75\n",
      "train Epoch: 5  , Loss: 2.3050,  Accuracy: 11.10\n",
      "val Epoch: 5  , Loss: 2.3061,  Accuracy: 10.00\n",
      "train Epoch: 6  , Loss: 2.3036,  Accuracy: 10.55\n",
      "val Epoch: 6  , Loss: 2.3058,  Accuracy: 9.50\n",
      "train Epoch: 7  , Loss: 2.3039,  Accuracy: 10.50\n",
      "val Epoch: 7  , Loss: 2.3055,  Accuracy: 10.00\n",
      "train Epoch: 8  , Loss: 2.3042,  Accuracy: 10.30\n",
      "val Epoch: 8  , Loss: 2.3053,  Accuracy: 10.75\n",
      "train Epoch: 9  , Loss: 2.3046,  Accuracy: 9.65\n",
      "val Epoch: 9  , Loss: 2.3050,  Accuracy: 11.00\n",
      "train Epoch: 10  , Loss: 2.3054,  Accuracy: 10.30\n",
      "val Epoch: 10  , Loss: 2.3048,  Accuracy: 10.50\n",
      "train Epoch: 11  , Loss: 2.3051,  Accuracy: 10.30\n",
      "val Epoch: 11  , Loss: 2.3045,  Accuracy: 11.00\n",
      "train Epoch: 12  , Loss: 2.3038,  Accuracy: 10.20\n",
      "val Epoch: 12  , Loss: 2.3043,  Accuracy: 11.00\n",
      "train Epoch: 13  , Loss: 2.3046,  Accuracy: 10.25\n",
      "val Epoch: 13  , Loss: 2.3041,  Accuracy: 12.00\n",
      "train Epoch: 14  , Loss: 2.3034,  Accuracy: 10.30\n",
      "val Epoch: 14  , Loss: 2.3039,  Accuracy: 12.00\n",
      "train Epoch: 15  , Loss: 2.3040,  Accuracy: 9.45\n",
      "val Epoch: 15  , Loss: 2.3037,  Accuracy: 11.25\n",
      "train Epoch: 16  , Loss: 2.3024,  Accuracy: 10.70\n",
      "val Epoch: 16  , Loss: 2.3035,  Accuracy: 11.25\n",
      "train Epoch: 17  , Loss: 2.3023,  Accuracy: 11.40\n",
      "val Epoch: 17  , Loss: 2.3033,  Accuracy: 11.25\n",
      "train Epoch: 18  , Loss: 2.3035,  Accuracy: 10.65\n",
      "val Epoch: 18  , Loss: 2.3031,  Accuracy: 11.25\n",
      "train Epoch: 19  , Loss: 2.3039,  Accuracy: 10.05\n",
      "val Epoch: 19  , Loss: 2.3030,  Accuracy: 11.25\n",
      "train Epoch: 20  , Loss: 2.3031,  Accuracy: 10.80\n",
      "val Epoch: 20  , Loss: 2.3028,  Accuracy: 11.50\n",
      "train Epoch: 21  , Loss: 2.3023,  Accuracy: 11.00\n",
      "val Epoch: 21  , Loss: 2.3027,  Accuracy: 11.75\n",
      "train Epoch: 22  , Loss: 2.3019,  Accuracy: 10.70\n",
      "val Epoch: 22  , Loss: 2.3025,  Accuracy: 11.75\n",
      "train Epoch: 23  , Loss: 2.3022,  Accuracy: 11.15\n",
      "val Epoch: 23  , Loss: 2.3024,  Accuracy: 11.75\n",
      "train Epoch: 24  , Loss: 2.3021,  Accuracy: 10.40\n",
      "val Epoch: 24  , Loss: 2.3023,  Accuracy: 11.75\n",
      "train Epoch: 25  , Loss: 2.3027,  Accuracy: 10.55\n",
      "val Epoch: 25  , Loss: 2.3021,  Accuracy: 12.00\n",
      "train Epoch: 26  , Loss: 2.3024,  Accuracy: 9.90\n",
      "val Epoch: 26  , Loss: 2.3020,  Accuracy: 11.75\n",
      "train Epoch: 27  , Loss: 2.3016,  Accuracy: 11.00\n",
      "val Epoch: 27  , Loss: 2.3019,  Accuracy: 12.00\n",
      "train Epoch: 28  , Loss: 2.3019,  Accuracy: 11.00\n",
      "val Epoch: 28  , Loss: 2.3017,  Accuracy: 12.00\n",
      "train Epoch: 29  , Loss: 2.3003,  Accuracy: 10.90\n",
      "val Epoch: 29  , Loss: 2.3016,  Accuracy: 12.00\n",
      "train Epoch: 30  , Loss: 2.3023,  Accuracy: 8.65\n",
      "val Epoch: 30  , Loss: 2.3015,  Accuracy: 12.25\n",
      "train Epoch: 31  , Loss: 2.3010,  Accuracy: 11.25\n",
      "val Epoch: 31  , Loss: 2.3014,  Accuracy: 12.50\n",
      "train Epoch: 32  , Loss: 2.3016,  Accuracy: 10.10\n",
      "val Epoch: 32  , Loss: 2.3013,  Accuracy: 12.50\n",
      "train Epoch: 33  , Loss: 2.3017,  Accuracy: 9.90\n",
      "val Epoch: 33  , Loss: 2.3012,  Accuracy: 11.75\n",
      "train Epoch: 34  , Loss: 2.3023,  Accuracy: 10.25\n",
      "val Epoch: 34  , Loss: 2.3011,  Accuracy: 11.00\n",
      "train Epoch: 35  , Loss: 2.3012,  Accuracy: 11.35\n",
      "val Epoch: 35  , Loss: 2.3010,  Accuracy: 11.25\n",
      "train Epoch: 36  , Loss: 2.3014,  Accuracy: 10.25\n",
      "val Epoch: 36  , Loss: 2.3009,  Accuracy: 11.50\n",
      "train Epoch: 37  , Loss: 2.3013,  Accuracy: 11.85\n",
      "val Epoch: 37  , Loss: 2.3008,  Accuracy: 11.75\n",
      "train Epoch: 38  , Loss: 2.3021,  Accuracy: 10.55\n",
      "val Epoch: 38  , Loss: 2.3007,  Accuracy: 11.50\n",
      "train Epoch: 39  , Loss: 2.3017,  Accuracy: 11.45\n",
      "val Epoch: 39  , Loss: 2.3006,  Accuracy: 11.50\n",
      "train Epoch: 40  , Loss: 2.3018,  Accuracy: 11.40\n",
      "val Epoch: 40  , Loss: 2.3005,  Accuracy: 10.75\n",
      "train Epoch: 41  , Loss: 2.3012,  Accuracy: 9.85\n",
      "val Epoch: 41  , Loss: 2.3004,  Accuracy: 10.50\n",
      "train Epoch: 42  , Loss: 2.3014,  Accuracy: 11.25\n",
      "val Epoch: 42  , Loss: 2.3004,  Accuracy: 10.75\n",
      "train Epoch: 43  , Loss: 2.3004,  Accuracy: 11.00\n",
      "val Epoch: 43  , Loss: 2.3003,  Accuracy: 11.75\n",
      "train Epoch: 44  , Loss: 2.3010,  Accuracy: 11.30\n",
      "val Epoch: 44  , Loss: 2.3002,  Accuracy: 12.25\n",
      "train Epoch: 45  , Loss: 2.3005,  Accuracy: 11.60\n",
      "val Epoch: 45  , Loss: 2.3001,  Accuracy: 12.25\n",
      "train Epoch: 46  , Loss: 2.3019,  Accuracy: 11.05\n",
      "val Epoch: 46  , Loss: 2.3000,  Accuracy: 11.75\n",
      "train Epoch: 47  , Loss: 2.3001,  Accuracy: 11.25\n",
      "val Epoch: 47  , Loss: 2.2999,  Accuracy: 12.00\n",
      "train Epoch: 48  , Loss: 2.3008,  Accuracy: 10.30\n",
      "val Epoch: 48  , Loss: 2.2998,  Accuracy: 11.25\n",
      "train Epoch: 49  , Loss: 2.3014,  Accuracy: 10.60\n",
      "val Epoch: 49  , Loss: 2.2997,  Accuracy: 11.75\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    "    return acc.value()[0]\n",
    "\n",
    "num_epochs = 50\n",
    "evaluate_every_epoch = 1\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        # Project Layer\n",
    "        self.project_layer = nn.Linear(75, 200)\n",
    "        self.project_layer_2 = nn.Linear(200, 300)\n",
    "        # Recurrent Layer\n",
    "        self.recurrent_layer = nn.LSTM(300, 400, batch_first = True)\n",
    "        self.recurrent_layer_2 = nn.LSTM(400, 400, batch_first = True) \n",
    "        # Classify Layer\n",
    "        self.classify_layer = nn.Linear(400, 200)\n",
    "        self.classify_layer_2 = nn.Linear(200, 10)\n",
    "        # Regularization Layer\n",
    "        self.regularization = nn.Dropout(0.2)\n",
    "\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs = self.project_layer(input)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer_2(rnn_outputs))\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_2(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_2(rnn_outputs) \n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.2119,  Accuracy: 14.35\n",
      "val Epoch: 0  , Loss: 1.8131,  Accuracy: 25.25\n",
      "train Epoch: 1  , Loss: 1.7097,  Accuracy: 33.35\n",
      "val Epoch: 1  , Loss: 1.5020,  Accuracy: 44.75\n",
      "train Epoch: 2  , Loss: 1.2825,  Accuracy: 49.70\n",
      "val Epoch: 2  , Loss: 1.1590,  Accuracy: 59.50\n",
      "train Epoch: 3  , Loss: 1.1051,  Accuracy: 59.30\n",
      "val Epoch: 3  , Loss: 1.1865,  Accuracy: 57.50\n",
      "train Epoch: 4  , Loss: 0.9574,  Accuracy: 66.40\n",
      "val Epoch: 4  , Loss: 1.0638,  Accuracy: 66.25\n",
      "train Epoch: 5  , Loss: 0.8627,  Accuracy: 67.95\n",
      "val Epoch: 5  , Loss: 1.0223,  Accuracy: 67.25\n",
      "train Epoch: 6  , Loss: 0.7773,  Accuracy: 71.95\n",
      "val Epoch: 6  , Loss: 1.0449,  Accuracy: 67.50\n",
      "train Epoch: 7  , Loss: 0.7466,  Accuracy: 72.40\n",
      "val Epoch: 7  , Loss: 0.8345,  Accuracy: 71.75\n",
      "train Epoch: 8  , Loss: 0.6146,  Accuracy: 77.65\n",
      "val Epoch: 8  , Loss: 0.7453,  Accuracy: 77.50\n",
      "train Epoch: 9  , Loss: 0.5984,  Accuracy: 78.45\n",
      "val Epoch: 9  , Loss: 0.7699,  Accuracy: 77.25\n",
      "train Epoch: 10  , Loss: 0.6825,  Accuracy: 74.65\n",
      "val Epoch: 10  , Loss: 0.9597,  Accuracy: 71.75\n",
      "train Epoch: 11  , Loss: 0.5754,  Accuracy: 79.35\n",
      "val Epoch: 11  , Loss: 0.7525,  Accuracy: 76.75\n",
      "train Epoch: 12  , Loss: 0.5340,  Accuracy: 80.45\n",
      "val Epoch: 12  , Loss: 0.7717,  Accuracy: 76.50\n",
      "train Epoch: 13  , Loss: 0.4573,  Accuracy: 83.40\n",
      "val Epoch: 13  , Loss: 0.7164,  Accuracy: 76.50\n",
      "train Epoch: 14  , Loss: 0.4484,  Accuracy: 82.90\n",
      "val Epoch: 14  , Loss: 0.8370,  Accuracy: 75.75\n",
      "train Epoch: 15  , Loss: 0.4306,  Accuracy: 83.65\n",
      "val Epoch: 15  , Loss: 0.8850,  Accuracy: 76.00\n",
      "train Epoch: 16  , Loss: 0.4185,  Accuracy: 83.95\n",
      "val Epoch: 16  , Loss: 0.7518,  Accuracy: 80.75\n",
      "train Epoch: 17  , Loss: 0.3702,  Accuracy: 86.35\n",
      "val Epoch: 17  , Loss: 0.8877,  Accuracy: 73.75\n",
      "train Epoch: 18  , Loss: 0.4616,  Accuracy: 83.00\n",
      "val Epoch: 18  , Loss: 0.8185,  Accuracy: 77.25\n",
      "train Epoch: 19  , Loss: 0.3574,  Accuracy: 86.75\n",
      "val Epoch: 19  , Loss: 0.9312,  Accuracy: 73.25\n",
      "train Epoch: 20  , Loss: 0.3784,  Accuracy: 85.70\n",
      "val Epoch: 20  , Loss: 0.9276,  Accuracy: 72.25\n",
      "train Epoch: 21  , Loss: 0.3906,  Accuracy: 85.95\n",
      "val Epoch: 21  , Loss: 0.7117,  Accuracy: 79.75\n",
      "train Epoch: 22  , Loss: 0.3112,  Accuracy: 88.30\n",
      "val Epoch: 22  , Loss: 0.8348,  Accuracy: 74.50\n",
      "train Epoch: 23  , Loss: 0.3117,  Accuracy: 88.50\n",
      "val Epoch: 23  , Loss: 0.8885,  Accuracy: 76.50\n",
      "train Epoch: 24  , Loss: 0.2432,  Accuracy: 91.60\n",
      "val Epoch: 24  , Loss: 0.8427,  Accuracy: 79.75\n",
      "train Epoch: 25  , Loss: 0.2477,  Accuracy: 91.75\n",
      "val Epoch: 25  , Loss: 0.8085,  Accuracy: 80.00\n",
      "train Epoch: 26  , Loss: 0.2311,  Accuracy: 92.00\n",
      "val Epoch: 26  , Loss: 0.9792,  Accuracy: 78.25\n",
      "train Epoch: 27  , Loss: 0.2756,  Accuracy: 90.15\n",
      "val Epoch: 27  , Loss: 0.8648,  Accuracy: 77.25\n",
      "train Epoch: 28  , Loss: 0.2487,  Accuracy: 90.50\n",
      "val Epoch: 28  , Loss: 1.0293,  Accuracy: 74.25\n",
      "train Epoch: 29  , Loss: 0.2602,  Accuracy: 90.30\n",
      "val Epoch: 29  , Loss: 0.9859,  Accuracy: 75.50\n",
      "train Epoch: 30  , Loss: 0.1899,  Accuracy: 93.10\n",
      "val Epoch: 30  , Loss: 1.0044,  Accuracy: 77.00\n",
      "train Epoch: 31  , Loss: 0.2616,  Accuracy: 90.95\n",
      "val Epoch: 31  , Loss: 0.8700,  Accuracy: 77.50\n",
      "train Epoch: 32  , Loss: 0.2919,  Accuracy: 89.35\n",
      "val Epoch: 32  , Loss: 0.9586,  Accuracy: 78.00\n",
      "train Epoch: 33  , Loss: 0.2649,  Accuracy: 90.80\n",
      "val Epoch: 33  , Loss: 0.9722,  Accuracy: 78.25\n",
      "train Epoch: 34  , Loss: 0.1699,  Accuracy: 93.55\n",
      "val Epoch: 34  , Loss: 0.8806,  Accuracy: 79.00\n",
      "train Epoch: 35  , Loss: 0.1484,  Accuracy: 94.25\n",
      "val Epoch: 35  , Loss: 1.0022,  Accuracy: 75.75\n",
      "train Epoch: 36  , Loss: 0.1549,  Accuracy: 94.15\n",
      "val Epoch: 36  , Loss: 1.0645,  Accuracy: 76.25\n",
      "train Epoch: 37  , Loss: 0.1224,  Accuracy: 95.60\n",
      "val Epoch: 37  , Loss: 0.9299,  Accuracy: 79.25\n",
      "train Epoch: 38  , Loss: 0.1489,  Accuracy: 94.40\n",
      "val Epoch: 38  , Loss: 1.0647,  Accuracy: 78.00\n",
      "train Epoch: 39  , Loss: 0.1016,  Accuracy: 96.35\n",
      "val Epoch: 39  , Loss: 1.0550,  Accuracy: 77.25\n",
      "train Epoch: 40  , Loss: 0.2019,  Accuracy: 93.65\n",
      "val Epoch: 40  , Loss: 0.9574,  Accuracy: 78.25\n",
      "train Epoch: 41  , Loss: 0.1362,  Accuracy: 95.35\n",
      "val Epoch: 41  , Loss: 1.1258,  Accuracy: 76.75\n",
      "train Epoch: 42  , Loss: 0.1573,  Accuracy: 94.50\n",
      "val Epoch: 42  , Loss: 0.9923,  Accuracy: 76.00\n",
      "train Epoch: 43  , Loss: 0.1272,  Accuracy: 95.35\n",
      "val Epoch: 43  , Loss: 1.0112,  Accuracy: 80.25\n",
      "train Epoch: 44  , Loss: 0.1225,  Accuracy: 96.05\n",
      "val Epoch: 44  , Loss: 1.0605,  Accuracy: 78.25\n",
      "train Epoch: 45  , Loss: 0.2965,  Accuracy: 90.40\n",
      "val Epoch: 45  , Loss: 0.9559,  Accuracy: 78.00\n",
      "train Epoch: 46  , Loss: 0.1803,  Accuracy: 93.15\n",
      "val Epoch: 46  , Loss: 0.8924,  Accuracy: 80.25\n",
      "train Epoch: 47  , Loss: 0.0725,  Accuracy: 97.65\n",
      "val Epoch: 47  , Loss: 0.8808,  Accuracy: 81.25\n",
      "train Epoch: 48  , Loss: 0.0772,  Accuracy: 97.45\n",
      "val Epoch: 48  , Loss: 0.9585,  Accuracy: 81.00\n",
      "train Epoch: 49  , Loss: 0.1038,  Accuracy: 96.65\n",
      "val Epoch: 49  , Loss: 1.0631,  Accuracy: 78.75\n",
      "train Epoch: 50  , Loss: 0.1659,  Accuracy: 94.75\n",
      "val Epoch: 50  , Loss: 0.8562,  Accuracy: 80.25\n",
      "train Epoch: 51  , Loss: 0.1305,  Accuracy: 95.65\n",
      "val Epoch: 51  , Loss: 1.0875,  Accuracy: 78.25\n",
      "train Epoch: 52  , Loss: 0.0925,  Accuracy: 96.85\n",
      "val Epoch: 52  , Loss: 1.0873,  Accuracy: 78.75\n",
      "train Epoch: 53  , Loss: 0.0546,  Accuracy: 98.05\n",
      "val Epoch: 53  , Loss: 1.0593,  Accuracy: 79.25\n",
      "train Epoch: 54  , Loss: 0.0546,  Accuracy: 98.35\n",
      "val Epoch: 54  , Loss: 1.2952,  Accuracy: 76.75\n",
      "train Epoch: 55  , Loss: 0.0914,  Accuracy: 97.05\n",
      "val Epoch: 55  , Loss: 1.0487,  Accuracy: 80.00\n",
      "train Epoch: 56  , Loss: 0.0316,  Accuracy: 99.10\n",
      "val Epoch: 56  , Loss: 1.0601,  Accuracy: 80.50\n",
      "train Epoch: 57  , Loss: 0.0129,  Accuracy: 99.65\n",
      "val Epoch: 57  , Loss: 1.1787,  Accuracy: 78.50\n",
      "train Epoch: 58  , Loss: 0.0140,  Accuracy: 99.65\n",
      "val Epoch: 58  , Loss: 1.2495,  Accuracy: 79.00\n",
      "train Epoch: 59  , Loss: 0.0341,  Accuracy: 98.70\n",
      "val Epoch: 59  , Loss: 1.2927,  Accuracy: 77.00\n",
      "train Epoch: 60  , Loss: 0.1317,  Accuracy: 95.65\n",
      "val Epoch: 60  , Loss: 1.2596,  Accuracy: 75.75\n",
      "train Epoch: 61  , Loss: 0.1394,  Accuracy: 95.05\n",
      "val Epoch: 61  , Loss: 1.1185,  Accuracy: 78.25\n",
      "train Epoch: 62  , Loss: 0.1483,  Accuracy: 95.40\n",
      "val Epoch: 62  , Loss: 1.1005,  Accuracy: 78.75\n",
      "train Epoch: 63  , Loss: 0.1236,  Accuracy: 95.75\n",
      "val Epoch: 63  , Loss: 1.0977,  Accuracy: 79.75\n",
      "train Epoch: 64  , Loss: 0.1022,  Accuracy: 96.40\n",
      "val Epoch: 64  , Loss: 1.0982,  Accuracy: 79.25\n",
      "train Epoch: 65  , Loss: 0.2633,  Accuracy: 92.65\n",
      "val Epoch: 65  , Loss: 0.9970,  Accuracy: 76.50\n",
      "train Epoch: 66  , Loss: 0.1645,  Accuracy: 94.05\n",
      "val Epoch: 66  , Loss: 1.1370,  Accuracy: 75.75\n",
      "train Epoch: 67  , Loss: 0.0808,  Accuracy: 97.40\n",
      "val Epoch: 67  , Loss: 1.0262,  Accuracy: 77.50\n",
      "train Epoch: 68  , Loss: 0.0684,  Accuracy: 98.00\n",
      "val Epoch: 68  , Loss: 1.0389,  Accuracy: 79.75\n",
      "train Epoch: 69  , Loss: 0.0344,  Accuracy: 98.85\n",
      "val Epoch: 69  , Loss: 1.0433,  Accuracy: 79.50\n",
      "train Epoch: 70  , Loss: 0.0476,  Accuracy: 98.55\n",
      "val Epoch: 70  , Loss: 1.1646,  Accuracy: 80.00\n",
      "train Epoch: 71  , Loss: 0.0418,  Accuracy: 98.70\n",
      "val Epoch: 71  , Loss: 0.9856,  Accuracy: 80.75\n",
      "train Epoch: 72  , Loss: 0.0325,  Accuracy: 98.95\n",
      "val Epoch: 72  , Loss: 1.1039,  Accuracy: 80.00\n",
      "train Epoch: 73  , Loss: 0.0689,  Accuracy: 97.95\n",
      "val Epoch: 73  , Loss: 1.0388,  Accuracy: 79.75\n",
      "train Epoch: 74  , Loss: 0.0689,  Accuracy: 97.70\n",
      "val Epoch: 74  , Loss: 1.1603,  Accuracy: 77.25\n",
      "train Epoch: 75  , Loss: 0.0685,  Accuracy: 97.80\n",
      "val Epoch: 75  , Loss: 1.1643,  Accuracy: 76.50\n",
      "train Epoch: 76  , Loss: 0.0619,  Accuracy: 97.75\n",
      "val Epoch: 76  , Loss: 1.1910,  Accuracy: 80.00\n",
      "train Epoch: 77  , Loss: 0.0961,  Accuracy: 97.00\n",
      "val Epoch: 77  , Loss: 1.0125,  Accuracy: 82.25\n",
      "train Epoch: 78  , Loss: 0.0675,  Accuracy: 97.65\n",
      "val Epoch: 78  , Loss: 1.0319,  Accuracy: 79.50\n",
      "train Epoch: 79  , Loss: 0.1063,  Accuracy: 96.95\n",
      "val Epoch: 79  , Loss: 1.2238,  Accuracy: 78.50\n",
      "train Epoch: 80  , Loss: 0.1534,  Accuracy: 95.25\n",
      "val Epoch: 80  , Loss: 1.0687,  Accuracy: 78.25\n",
      "train Epoch: 81  , Loss: 0.0878,  Accuracy: 96.90\n",
      "val Epoch: 81  , Loss: 1.0309,  Accuracy: 79.50\n",
      "train Epoch: 82  , Loss: 0.0611,  Accuracy: 97.50\n",
      "val Epoch: 82  , Loss: 1.0189,  Accuracy: 80.75\n",
      "train Epoch: 83  , Loss: 0.0497,  Accuracy: 98.35\n",
      "val Epoch: 83  , Loss: 1.1677,  Accuracy: 77.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 84  , Loss: 0.0190,  Accuracy: 99.40\n",
      "val Epoch: 84  , Loss: 1.0123,  Accuracy: 81.25\n",
      "train Epoch: 85  , Loss: 0.0078,  Accuracy: 99.80\n",
      "val Epoch: 85  , Loss: 1.0741,  Accuracy: 79.50\n",
      "train Epoch: 86  , Loss: 0.0083,  Accuracy: 99.80\n",
      "val Epoch: 86  , Loss: 1.1790,  Accuracy: 79.00\n",
      "train Epoch: 87  , Loss: 0.0165,  Accuracy: 99.55\n",
      "val Epoch: 87  , Loss: 1.2406,  Accuracy: 79.25\n",
      "train Epoch: 88  , Loss: 0.0250,  Accuracy: 99.15\n",
      "val Epoch: 88  , Loss: 1.1858,  Accuracy: 80.25\n",
      "train Epoch: 89  , Loss: 0.0894,  Accuracy: 97.40\n",
      "val Epoch: 89  , Loss: 1.2240,  Accuracy: 77.75\n",
      "train Epoch: 90  , Loss: 0.1178,  Accuracy: 96.05\n",
      "val Epoch: 90  , Loss: 1.0980,  Accuracy: 78.25\n",
      "train Epoch: 91  , Loss: 0.0925,  Accuracy: 97.25\n",
      "val Epoch: 91  , Loss: 1.2473,  Accuracy: 78.00\n",
      "train Epoch: 92  , Loss: 0.1339,  Accuracy: 95.55\n",
      "val Epoch: 92  , Loss: 1.1300,  Accuracy: 78.25\n",
      "train Epoch: 93  , Loss: 0.0668,  Accuracy: 97.45\n",
      "val Epoch: 93  , Loss: 1.2820,  Accuracy: 75.75\n",
      "train Epoch: 94  , Loss: 0.0471,  Accuracy: 98.50\n",
      "val Epoch: 94  , Loss: 1.3126,  Accuracy: 78.75\n",
      "train Epoch: 95  , Loss: 0.1014,  Accuracy: 96.65\n",
      "val Epoch: 95  , Loss: 1.0014,  Accuracy: 80.50\n",
      "train Epoch: 96  , Loss: 0.0624,  Accuracy: 98.00\n",
      "val Epoch: 96  , Loss: 1.1258,  Accuracy: 78.50\n",
      "train Epoch: 97  , Loss: 0.0536,  Accuracy: 98.20\n",
      "val Epoch: 97  , Loss: 1.1566,  Accuracy: 79.75\n",
      "train Epoch: 98  , Loss: 0.0255,  Accuracy: 99.00\n",
      "val Epoch: 98  , Loss: 1.2215,  Accuracy: 79.25\n",
      "train Epoch: 99  , Loss: 0.0915,  Accuracy: 97.20\n",
      "val Epoch: 99  , Loss: 1.4590,  Accuracy: 74.50\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    "    return acc.value()[0]\n",
    "\n",
    "num_epochs = 100\n",
    "evaluate_every_epoch = 1\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 1.6520,  Accuracy: 36.30\n",
      "val Epoch: 0  , Loss: 1.5488,  Accuracy: 43.00\n",
      "train Epoch: 1  , Loss: 1.6100,  Accuracy: 39.30\n",
      "train Epoch: 2  , Loss: 1.5872,  Accuracy: 39.85\n",
      "train Epoch: 3  , Loss: 1.5950,  Accuracy: 39.20\n",
      "train Epoch: 4  , Loss: 1.5771,  Accuracy: 40.20\n",
      "train Epoch: 5  , Loss: 1.5656,  Accuracy: 39.50\n",
      "val Epoch: 5  , Loss: 1.5153,  Accuracy: 46.25\n",
      "train Epoch: 6  , Loss: 1.5790,  Accuracy: 39.90\n",
      "train Epoch: 7  , Loss: 1.5809,  Accuracy: 39.65\n",
      "train Epoch: 8  , Loss: 1.5732,  Accuracy: 40.45\n",
      "train Epoch: 9  , Loss: 1.5610,  Accuracy: 40.05\n",
      "train Epoch: 10  , Loss: 1.5423,  Accuracy: 41.55\n",
      "val Epoch: 10  , Loss: 1.5011,  Accuracy: 43.50\n",
      "train Epoch: 11  , Loss: 1.5667,  Accuracy: 42.45\n",
      "train Epoch: 12  , Loss: 1.5832,  Accuracy: 39.65\n",
      "train Epoch: 13  , Loss: 1.5465,  Accuracy: 40.85\n",
      "train Epoch: 14  , Loss: 1.5442,  Accuracy: 41.75\n",
      "train Epoch: 15  , Loss: 1.5198,  Accuracy: 42.30\n",
      "val Epoch: 15  , Loss: 1.4974,  Accuracy: 47.00\n",
      "train Epoch: 16  , Loss: 1.5404,  Accuracy: 40.95\n",
      "train Epoch: 17  , Loss: 1.5237,  Accuracy: 41.80\n",
      "train Epoch: 18  , Loss: 1.5179,  Accuracy: 41.80\n",
      "train Epoch: 19  , Loss: 1.5244,  Accuracy: 42.25\n",
      "train Epoch: 20  , Loss: 1.5259,  Accuracy: 41.05\n",
      "val Epoch: 20  , Loss: 1.4919,  Accuracy: 44.00\n",
      "train Epoch: 21  , Loss: 1.5172,  Accuracy: 42.15\n",
      "train Epoch: 22  , Loss: 1.4998,  Accuracy: 43.40\n",
      "train Epoch: 23  , Loss: 1.4964,  Accuracy: 42.30\n",
      "train Epoch: 24  , Loss: 1.4885,  Accuracy: 43.40\n",
      "train Epoch: 25  , Loss: 1.5086,  Accuracy: 42.40\n",
      "val Epoch: 25  , Loss: 1.5105,  Accuracy: 43.25\n",
      "train Epoch: 26  , Loss: 1.4793,  Accuracy: 43.30\n",
      "train Epoch: 27  , Loss: 1.4774,  Accuracy: 43.55\n",
      "train Epoch: 28  , Loss: 1.5010,  Accuracy: 42.90\n",
      "train Epoch: 29  , Loss: 1.4708,  Accuracy: 44.20\n",
      "train Epoch: 30  , Loss: 1.4867,  Accuracy: 43.45\n",
      "val Epoch: 30  , Loss: 1.4913,  Accuracy: 45.75\n",
      "train Epoch: 31  , Loss: 1.4720,  Accuracy: 44.15\n",
      "train Epoch: 32  , Loss: 1.4481,  Accuracy: 44.45\n",
      "train Epoch: 33  , Loss: 1.4714,  Accuracy: 43.85\n",
      "train Epoch: 34  , Loss: 1.4397,  Accuracy: 44.95\n",
      "train Epoch: 35  , Loss: 1.4440,  Accuracy: 44.40\n",
      "val Epoch: 35  , Loss: 1.4669,  Accuracy: 46.50\n",
      "train Epoch: 36  , Loss: 1.4537,  Accuracy: 44.85\n",
      "train Epoch: 37  , Loss: 1.4312,  Accuracy: 46.00\n",
      "train Epoch: 38  , Loss: 1.4393,  Accuracy: 44.95\n",
      "train Epoch: 39  , Loss: 1.4162,  Accuracy: 46.35\n",
      "train Epoch: 40  , Loss: 1.4225,  Accuracy: 45.70\n",
      "val Epoch: 40  , Loss: 1.4675,  Accuracy: 46.25\n",
      "train Epoch: 41  , Loss: 1.3963,  Accuracy: 46.05\n",
      "train Epoch: 42  , Loss: 1.3967,  Accuracy: 45.25\n",
      "train Epoch: 43  , Loss: 1.3959,  Accuracy: 46.65\n",
      "train Epoch: 44  , Loss: 1.4040,  Accuracy: 46.40\n",
      "train Epoch: 45  , Loss: 1.3802,  Accuracy: 46.30\n",
      "val Epoch: 45  , Loss: 1.4530,  Accuracy: 46.50\n",
      "train Epoch: 46  , Loss: 1.3686,  Accuracy: 48.30\n",
      "train Epoch: 47  , Loss: 1.3571,  Accuracy: 47.90\n",
      "train Epoch: 48  , Loss: 1.3579,  Accuracy: 48.55\n",
      "train Epoch: 49  , Loss: 1.3551,  Accuracy: 48.60\n",
      "train Epoch: 50  , Loss: 1.3618,  Accuracy: 48.50\n",
      "val Epoch: 50  , Loss: 1.4501,  Accuracy: 47.75\n",
      "train Epoch: 51  , Loss: 1.3387,  Accuracy: 48.15\n",
      "train Epoch: 52  , Loss: 1.3543,  Accuracy: 48.10\n",
      "train Epoch: 53  , Loss: 1.3376,  Accuracy: 46.80\n",
      "train Epoch: 54  , Loss: 1.3187,  Accuracy: 49.65\n",
      "train Epoch: 55  , Loss: 1.3314,  Accuracy: 48.60\n",
      "val Epoch: 55  , Loss: 1.4478,  Accuracy: 47.00\n",
      "train Epoch: 56  , Loss: 1.3134,  Accuracy: 49.10\n",
      "train Epoch: 57  , Loss: 1.3015,  Accuracy: 50.35\n",
      "train Epoch: 58  , Loss: 1.3053,  Accuracy: 50.60\n",
      "train Epoch: 59  , Loss: 1.2884,  Accuracy: 51.05\n",
      "train Epoch: 60  , Loss: 1.2982,  Accuracy: 50.20\n",
      "val Epoch: 60  , Loss: 1.4344,  Accuracy: 48.25\n",
      "train Epoch: 61  , Loss: 1.2798,  Accuracy: 49.80\n",
      "train Epoch: 62  , Loss: 1.2734,  Accuracy: 50.80\n",
      "train Epoch: 63  , Loss: 1.2753,  Accuracy: 51.55\n",
      "train Epoch: 64  , Loss: 1.2758,  Accuracy: 50.00\n",
      "train Epoch: 65  , Loss: 1.2429,  Accuracy: 52.00\n",
      "val Epoch: 65  , Loss: 1.4611,  Accuracy: 48.00\n",
      "train Epoch: 66  , Loss: 1.2564,  Accuracy: 51.70\n",
      "train Epoch: 67  , Loss: 1.2428,  Accuracy: 52.60\n",
      "train Epoch: 68  , Loss: 1.2429,  Accuracy: 52.10\n",
      "train Epoch: 69  , Loss: 1.2327,  Accuracy: 52.55\n",
      "train Epoch: 70  , Loss: 1.2376,  Accuracy: 52.80\n",
      "val Epoch: 70  , Loss: 1.4901,  Accuracy: 46.50\n",
      "train Epoch: 71  , Loss: 1.2348,  Accuracy: 52.50\n",
      "train Epoch: 72  , Loss: 1.2213,  Accuracy: 54.25\n",
      "train Epoch: 73  , Loss: 1.2166,  Accuracy: 54.65\n",
      "train Epoch: 74  , Loss: 1.2086,  Accuracy: 53.45\n",
      "train Epoch: 75  , Loss: 1.1969,  Accuracy: 52.85\n",
      "val Epoch: 75  , Loss: 1.4963,  Accuracy: 48.75\n",
      "train Epoch: 76  , Loss: 1.2004,  Accuracy: 54.40\n",
      "train Epoch: 77  , Loss: 1.1823,  Accuracy: 55.25\n",
      "train Epoch: 78  , Loss: 1.1618,  Accuracy: 55.15\n",
      "train Epoch: 79  , Loss: 1.1564,  Accuracy: 55.90\n",
      "train Epoch: 80  , Loss: 1.1735,  Accuracy: 54.95\n",
      "val Epoch: 80  , Loss: 1.5209,  Accuracy: 49.00\n",
      "train Epoch: 81  , Loss: 1.1450,  Accuracy: 56.70\n",
      "train Epoch: 82  , Loss: 1.1329,  Accuracy: 55.55\n",
      "train Epoch: 83  , Loss: 1.1530,  Accuracy: 55.60\n",
      "train Epoch: 84  , Loss: 1.1224,  Accuracy: 55.80\n",
      "train Epoch: 85  , Loss: 1.1160,  Accuracy: 57.30\n",
      "val Epoch: 85  , Loss: 1.5635,  Accuracy: 46.75\n",
      "train Epoch: 86  , Loss: 1.1247,  Accuracy: 57.80\n",
      "train Epoch: 87  , Loss: 1.1181,  Accuracy: 55.90\n",
      "train Epoch: 88  , Loss: 1.1252,  Accuracy: 56.55\n",
      "train Epoch: 89  , Loss: 1.1181,  Accuracy: 57.65\n",
      "train Epoch: 90  , Loss: 1.1236,  Accuracy: 56.05\n",
      "val Epoch: 90  , Loss: 1.5986,  Accuracy: 46.25\n",
      "train Epoch: 91  , Loss: 1.1437,  Accuracy: 56.80\n",
      "train Epoch: 92  , Loss: 1.0865,  Accuracy: 58.40\n",
      "train Epoch: 93  , Loss: 1.0997,  Accuracy: 56.80\n",
      "train Epoch: 94  , Loss: 1.0821,  Accuracy: 58.25\n",
      "train Epoch: 95  , Loss: 1.0785,  Accuracy: 58.90\n",
      "val Epoch: 95  , Loss: 1.6217,  Accuracy: 47.25\n",
      "train Epoch: 96  , Loss: 1.0558,  Accuracy: 59.10\n",
      "train Epoch: 97  , Loss: 1.0585,  Accuracy: 59.05\n",
      "train Epoch: 98  , Loss: 1.0512,  Accuracy: 59.25\n",
      "train Epoch: 99  , Loss: 1.0375,  Accuracy: 60.50\n",
      "train Epoch: 100  , Loss: 1.0343,  Accuracy: 59.60\n",
      "val Epoch: 100  , Loss: 1.6748,  Accuracy: 45.00\n",
      "train Epoch: 101  , Loss: 1.0524,  Accuracy: 60.75\n",
      "train Epoch: 102  , Loss: 1.0252,  Accuracy: 60.65\n",
      "train Epoch: 103  , Loss: 1.0004,  Accuracy: 61.60\n",
      "train Epoch: 104  , Loss: 1.0137,  Accuracy: 60.90\n",
      "train Epoch: 105  , Loss: 1.0101,  Accuracy: 61.25\n",
      "val Epoch: 105  , Loss: 1.7277,  Accuracy: 46.00\n",
      "train Epoch: 106  , Loss: 0.9717,  Accuracy: 62.70\n",
      "train Epoch: 107  , Loss: 1.0287,  Accuracy: 60.75\n",
      "train Epoch: 108  , Loss: 0.9754,  Accuracy: 62.20\n",
      "train Epoch: 109  , Loss: 0.9831,  Accuracy: 61.70\n",
      "train Epoch: 110  , Loss: 0.9479,  Accuracy: 64.65\n",
      "val Epoch: 110  , Loss: 1.7659,  Accuracy: 47.75\n",
      "train Epoch: 111  , Loss: 0.9606,  Accuracy: 63.00\n",
      "train Epoch: 112  , Loss: 0.9206,  Accuracy: 64.90\n",
      "train Epoch: 113  , Loss: 0.9672,  Accuracy: 62.30\n",
      "train Epoch: 114  , Loss: 0.9822,  Accuracy: 62.00\n",
      "train Epoch: 115  , Loss: 0.9275,  Accuracy: 65.80\n",
      "val Epoch: 115  , Loss: 1.7634,  Accuracy: 45.50\n",
      "train Epoch: 116  , Loss: 0.9738,  Accuracy: 62.50\n",
      "train Epoch: 117  , Loss: 0.9232,  Accuracy: 64.65\n",
      "train Epoch: 118  , Loss: 0.9397,  Accuracy: 63.35\n",
      "train Epoch: 119  , Loss: 0.9276,  Accuracy: 64.70\n",
      "train Epoch: 120  , Loss: 0.9154,  Accuracy: 63.90\n",
      "val Epoch: 120  , Loss: 1.8647,  Accuracy: 45.25\n",
      "train Epoch: 121  , Loss: 0.9221,  Accuracy: 64.90\n",
      "train Epoch: 122  , Loss: 0.8915,  Accuracy: 65.70\n",
      "train Epoch: 123  , Loss: 0.8958,  Accuracy: 64.85\n",
      "train Epoch: 124  , Loss: 0.8757,  Accuracy: 67.70\n",
      "train Epoch: 125  , Loss: 0.8664,  Accuracy: 66.85\n",
      "val Epoch: 125  , Loss: 1.8538,  Accuracy: 48.50\n",
      "train Epoch: 126  , Loss: 0.8623,  Accuracy: 67.65\n",
      "train Epoch: 127  , Loss: 0.8541,  Accuracy: 67.10\n",
      "train Epoch: 128  , Loss: 0.9034,  Accuracy: 65.05\n",
      "train Epoch: 129  , Loss: 0.8628,  Accuracy: 67.40\n",
      "train Epoch: 130  , Loss: 0.8199,  Accuracy: 69.15\n",
      "val Epoch: 130  , Loss: 1.9979,  Accuracy: 49.00\n",
      "train Epoch: 131  , Loss: 0.8285,  Accuracy: 68.30\n",
      "train Epoch: 132  , Loss: 0.8520,  Accuracy: 67.50\n",
      "train Epoch: 133  , Loss: 0.8306,  Accuracy: 67.85\n",
      "train Epoch: 134  , Loss: 0.8168,  Accuracy: 68.45\n",
      "train Epoch: 135  , Loss: 0.7943,  Accuracy: 69.45\n",
      "val Epoch: 135  , Loss: 2.0047,  Accuracy: 48.00\n",
      "train Epoch: 136  , Loss: 0.7968,  Accuracy: 70.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 137  , Loss: 0.7801,  Accuracy: 70.80\n",
      "train Epoch: 138  , Loss: 0.7794,  Accuracy: 69.65\n",
      "train Epoch: 139  , Loss: 0.7778,  Accuracy: 70.15\n",
      "train Epoch: 140  , Loss: 0.7721,  Accuracy: 71.20\n",
      "val Epoch: 140  , Loss: 2.0965,  Accuracy: 47.25\n",
      "train Epoch: 141  , Loss: 0.7805,  Accuracy: 70.10\n",
      "train Epoch: 142  , Loss: 0.8009,  Accuracy: 68.15\n",
      "train Epoch: 143  , Loss: 0.7889,  Accuracy: 69.35\n",
      "train Epoch: 144  , Loss: 0.7537,  Accuracy: 71.35\n",
      "train Epoch: 145  , Loss: 0.7648,  Accuracy: 70.30\n",
      "val Epoch: 145  , Loss: 2.1169,  Accuracy: 45.75\n",
      "train Epoch: 146  , Loss: 0.7585,  Accuracy: 70.95\n",
      "train Epoch: 147  , Loss: 0.7180,  Accuracy: 71.00\n",
      "train Epoch: 148  , Loss: 0.7510,  Accuracy: 71.05\n",
      "train Epoch: 149  , Loss: 0.7475,  Accuracy: 71.60\n",
      "train Epoch: 150  , Loss: 0.7223,  Accuracy: 72.35\n",
      "val Epoch: 150  , Loss: 2.2001,  Accuracy: 46.25\n",
      "train Epoch: 151  , Loss: 0.7079,  Accuracy: 72.45\n",
      "train Epoch: 152  , Loss: 0.7072,  Accuracy: 73.20\n",
      "train Epoch: 153  , Loss: 0.7166,  Accuracy: 72.00\n",
      "train Epoch: 154  , Loss: 0.6927,  Accuracy: 74.45\n",
      "train Epoch: 155  , Loss: 0.7118,  Accuracy: 72.85\n",
      "val Epoch: 155  , Loss: 2.2566,  Accuracy: 44.75\n",
      "train Epoch: 156  , Loss: 0.7014,  Accuracy: 73.90\n",
      "train Epoch: 157  , Loss: 0.7271,  Accuracy: 72.15\n",
      "train Epoch: 158  , Loss: 0.7022,  Accuracy: 72.70\n",
      "train Epoch: 159  , Loss: 0.6852,  Accuracy: 74.10\n",
      "train Epoch: 160  , Loss: 0.6631,  Accuracy: 74.75\n",
      "val Epoch: 160  , Loss: 2.3427,  Accuracy: 45.50\n",
      "train Epoch: 161  , Loss: 0.6535,  Accuracy: 74.80\n",
      "train Epoch: 162  , Loss: 0.6225,  Accuracy: 77.70\n",
      "train Epoch: 163  , Loss: 0.6417,  Accuracy: 76.35\n",
      "train Epoch: 164  , Loss: 0.6550,  Accuracy: 75.10\n",
      "train Epoch: 165  , Loss: 0.7072,  Accuracy: 73.80\n",
      "val Epoch: 165  , Loss: 2.3740,  Accuracy: 43.75\n",
      "train Epoch: 166  , Loss: 0.6655,  Accuracy: 75.40\n",
      "train Epoch: 167  , Loss: 0.6167,  Accuracy: 75.35\n",
      "train Epoch: 168  , Loss: 0.6225,  Accuracy: 76.55\n",
      "train Epoch: 169  , Loss: 0.6541,  Accuracy: 74.95\n",
      "train Epoch: 170  , Loss: 0.6290,  Accuracy: 76.15\n",
      "val Epoch: 170  , Loss: 2.4769,  Accuracy: 46.50\n",
      "train Epoch: 171  , Loss: 0.6167,  Accuracy: 76.30\n",
      "train Epoch: 172  , Loss: 0.6293,  Accuracy: 74.80\n",
      "train Epoch: 173  , Loss: 0.6030,  Accuracy: 77.55\n",
      "train Epoch: 174  , Loss: 0.6075,  Accuracy: 77.20\n",
      "train Epoch: 175  , Loss: 0.5967,  Accuracy: 78.00\n",
      "val Epoch: 175  , Loss: 2.3874,  Accuracy: 44.25\n",
      "train Epoch: 176  , Loss: 0.6083,  Accuracy: 76.70\n",
      "train Epoch: 177  , Loss: 0.5846,  Accuracy: 77.50\n",
      "train Epoch: 178  , Loss: 0.6259,  Accuracy: 75.65\n",
      "train Epoch: 179  , Loss: 0.6358,  Accuracy: 75.25\n",
      "train Epoch: 180  , Loss: 0.6000,  Accuracy: 77.45\n",
      "val Epoch: 180  , Loss: 2.5548,  Accuracy: 44.75\n",
      "train Epoch: 181  , Loss: 0.5852,  Accuracy: 77.30\n",
      "train Epoch: 182  , Loss: 0.5531,  Accuracy: 78.80\n",
      "train Epoch: 183  , Loss: 0.5781,  Accuracy: 77.75\n",
      "train Epoch: 184  , Loss: 0.5698,  Accuracy: 77.60\n",
      "train Epoch: 185  , Loss: 0.5826,  Accuracy: 77.55\n",
      "val Epoch: 185  , Loss: 2.7134,  Accuracy: 44.00\n",
      "train Epoch: 186  , Loss: 0.5518,  Accuracy: 78.25\n",
      "train Epoch: 187  , Loss: 0.5395,  Accuracy: 79.40\n",
      "train Epoch: 188  , Loss: 0.5871,  Accuracy: 78.45\n",
      "train Epoch: 189  , Loss: 0.5760,  Accuracy: 78.40\n",
      "train Epoch: 190  , Loss: 0.5461,  Accuracy: 79.10\n",
      "val Epoch: 190  , Loss: 2.7247,  Accuracy: 45.75\n",
      "train Epoch: 191  , Loss: 0.5460,  Accuracy: 79.40\n",
      "train Epoch: 192  , Loss: 0.5443,  Accuracy: 78.65\n",
      "train Epoch: 193  , Loss: 0.5412,  Accuracy: 79.15\n",
      "train Epoch: 194  , Loss: 0.5387,  Accuracy: 79.25\n",
      "train Epoch: 195  , Loss: 0.5501,  Accuracy: 78.45\n",
      "val Epoch: 195  , Loss: 2.7681,  Accuracy: 42.75\n",
      "train Epoch: 196  , Loss: 0.5119,  Accuracy: 81.20\n",
      "train Epoch: 197  , Loss: 0.5323,  Accuracy: 79.70\n",
      "train Epoch: 198  , Loss: 0.5410,  Accuracy: 79.35\n",
      "train Epoch: 199  , Loss: 0.5069,  Accuracy: 81.15\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    "    return acc.value()[0]\n",
    "\n",
    "num_epochs = 200\n",
    "evaluate_every_epoch = 5\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 - Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        # Project Layer\n",
    "        self.project_layer = nn.Linear(75, 200)\n",
    "        self.project_layer_2 = nn.Linear(200, 300)\n",
    "        # Recurrent Layer\n",
    "        self.recurrent_layer = nn.LSTM(300, 400, batch_first = True)\n",
    "        self.recurrent_layer_2 = nn.LSTM(400, 500, batch_first = True)\n",
    "        self.recurrent_layer_3 = nn.LSTM(500, 500, batch_first = True)\n",
    "        # Classify Layer\n",
    "        self.classify_layer = nn.Linear(500, 300)\n",
    "        self.classify_layer_2 = nn.Linear(300, 100)\n",
    "        self.classify_layer_3 = nn.Linear(100, 10)\n",
    "        # Regularization Layer\n",
    "        self.regularization = nn.Dropout(0.2)\n",
    "\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs = self.project_layer(input)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer_2(rnn_outputs))\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_2(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_3(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_2(rnn_outputs) \n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_3(rnn_outputs)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainModel_accuracy = []\n",
    "trainModel_loss = []\n",
    "valModel_accuracy = []\n",
    "valModel_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.2821,  Accuracy: 10.90\n",
      "val Epoch: 0  , Loss: 2.0604,  Accuracy: 16.25\n",
      "train Epoch: 1  , Loss: 1.9474,  Accuracy: 21.40\n",
      "val Epoch: 1  , Loss: 1.7137,  Accuracy: 30.50\n",
      "train Epoch: 2  , Loss: 1.5681,  Accuracy: 39.30\n",
      "val Epoch: 2  , Loss: 1.3732,  Accuracy: 46.50\n",
      "train Epoch: 3  , Loss: 1.2643,  Accuracy: 52.05\n",
      "val Epoch: 3  , Loss: 1.2528,  Accuracy: 55.00\n",
      "train Epoch: 4  , Loss: 1.1568,  Accuracy: 56.50\n",
      "val Epoch: 4  , Loss: 1.1053,  Accuracy: 61.00\n",
      "train Epoch: 5  , Loss: 1.0340,  Accuracy: 60.60\n",
      "val Epoch: 5  , Loss: 1.1374,  Accuracy: 60.00\n",
      "train Epoch: 6  , Loss: 0.9820,  Accuracy: 62.90\n",
      "val Epoch: 6  , Loss: 0.9880,  Accuracy: 63.75\n",
      "train Epoch: 7  , Loss: 0.9839,  Accuracy: 64.15\n",
      "val Epoch: 7  , Loss: 1.0897,  Accuracy: 62.50\n",
      "train Epoch: 8  , Loss: 0.8720,  Accuracy: 67.95\n",
      "val Epoch: 8  , Loss: 1.0317,  Accuracy: 66.25\n",
      "train Epoch: 9  , Loss: 0.8186,  Accuracy: 71.70\n",
      "val Epoch: 9  , Loss: 0.9211,  Accuracy: 68.50\n",
      "train Epoch: 10  , Loss: 0.8159,  Accuracy: 72.05\n",
      "val Epoch: 10  , Loss: 0.9202,  Accuracy: 68.75\n",
      "train Epoch: 11  , Loss: 0.6972,  Accuracy: 74.80\n",
      "val Epoch: 11  , Loss: 0.7889,  Accuracy: 74.25\n",
      "train Epoch: 12  , Loss: 0.6699,  Accuracy: 75.55\n",
      "val Epoch: 12  , Loss: 0.8966,  Accuracy: 71.75\n",
      "train Epoch: 13  , Loss: 0.6399,  Accuracy: 77.35\n",
      "val Epoch: 13  , Loss: 1.0428,  Accuracy: 67.75\n",
      "train Epoch: 14  , Loss: 0.5878,  Accuracy: 78.95\n",
      "val Epoch: 14  , Loss: 0.7907,  Accuracy: 77.00\n",
      "train Epoch: 15  , Loss: 0.5656,  Accuracy: 80.25\n",
      "val Epoch: 15  , Loss: 0.7998,  Accuracy: 76.50\n",
      "train Epoch: 16  , Loss: 0.5462,  Accuracy: 80.80\n",
      "val Epoch: 16  , Loss: 0.6425,  Accuracy: 82.75\n",
      "train Epoch: 17  , Loss: 0.5114,  Accuracy: 82.50\n",
      "val Epoch: 17  , Loss: 0.6633,  Accuracy: 81.00\n",
      "train Epoch: 18  , Loss: 0.4971,  Accuracy: 82.80\n",
      "val Epoch: 18  , Loss: 0.8153,  Accuracy: 77.50\n",
      "train Epoch: 19  , Loss: 0.5043,  Accuracy: 82.35\n",
      "val Epoch: 19  , Loss: 0.7287,  Accuracy: 77.50\n",
      "train Epoch: 20  , Loss: 0.4743,  Accuracy: 82.90\n",
      "val Epoch: 20  , Loss: 0.6428,  Accuracy: 83.25\n",
      "train Epoch: 21  , Loss: 0.4400,  Accuracy: 84.25\n",
      "val Epoch: 21  , Loss: 0.7365,  Accuracy: 79.00\n",
      "train Epoch: 22  , Loss: 0.4292,  Accuracy: 85.05\n",
      "val Epoch: 22  , Loss: 0.6738,  Accuracy: 81.00\n",
      "train Epoch: 23  , Loss: 0.4972,  Accuracy: 83.00\n",
      "val Epoch: 23  , Loss: 0.7255,  Accuracy: 80.25\n",
      "train Epoch: 24  , Loss: 0.3910,  Accuracy: 86.10\n",
      "val Epoch: 24  , Loss: 0.9006,  Accuracy: 78.00\n",
      "train Epoch: 25  , Loss: 0.3872,  Accuracy: 86.00\n",
      "val Epoch: 25  , Loss: 0.7001,  Accuracy: 79.75\n",
      "train Epoch: 26  , Loss: 0.3742,  Accuracy: 86.60\n",
      "val Epoch: 26  , Loss: 0.7889,  Accuracy: 80.00\n",
      "train Epoch: 27  , Loss: 0.3958,  Accuracy: 86.25\n",
      "val Epoch: 27  , Loss: 0.6464,  Accuracy: 82.25\n",
      "train Epoch: 28  , Loss: 0.3983,  Accuracy: 85.55\n",
      "val Epoch: 28  , Loss: 0.7657,  Accuracy: 79.00\n",
      "train Epoch: 29  , Loss: 0.4430,  Accuracy: 85.20\n",
      "val Epoch: 29  , Loss: 0.7257,  Accuracy: 80.00\n",
      "train Epoch: 30  , Loss: 0.3044,  Accuracy: 89.00\n",
      "val Epoch: 30  , Loss: 0.8912,  Accuracy: 78.50\n",
      "train Epoch: 31  , Loss: 0.2609,  Accuracy: 90.65\n",
      "val Epoch: 31  , Loss: 0.7935,  Accuracy: 78.50\n",
      "train Epoch: 32  , Loss: 0.2490,  Accuracy: 91.00\n",
      "val Epoch: 32  , Loss: 0.7800,  Accuracy: 79.50\n",
      "train Epoch: 33  , Loss: 0.2677,  Accuracy: 90.05\n",
      "val Epoch: 33  , Loss: 0.9119,  Accuracy: 78.25\n",
      "train Epoch: 34  , Loss: 0.2928,  Accuracy: 89.35\n",
      "val Epoch: 34  , Loss: 0.7430,  Accuracy: 80.00\n",
      "train Epoch: 35  , Loss: 0.3558,  Accuracy: 87.45\n",
      "val Epoch: 35  , Loss: 0.8063,  Accuracy: 78.25\n",
      "train Epoch: 36  , Loss: 0.2692,  Accuracy: 90.75\n",
      "val Epoch: 36  , Loss: 0.7379,  Accuracy: 82.75\n",
      "train Epoch: 37  , Loss: 0.2814,  Accuracy: 90.70\n",
      "val Epoch: 37  , Loss: 0.9949,  Accuracy: 76.75\n",
      "train Epoch: 38  , Loss: 0.2201,  Accuracy: 92.10\n",
      "val Epoch: 38  , Loss: 0.9517,  Accuracy: 78.75\n",
      "train Epoch: 39  , Loss: 0.2276,  Accuracy: 91.60\n",
      "val Epoch: 39  , Loss: 0.8651,  Accuracy: 79.50\n",
      "train Epoch: 40  , Loss: 0.1666,  Accuracy: 94.25\n",
      "val Epoch: 40  , Loss: 0.9678,  Accuracy: 80.00\n",
      "train Epoch: 41  , Loss: 0.2327,  Accuracy: 92.85\n",
      "val Epoch: 41  , Loss: 0.9745,  Accuracy: 77.00\n",
      "train Epoch: 42  , Loss: 0.2617,  Accuracy: 91.20\n",
      "val Epoch: 42  , Loss: 0.7854,  Accuracy: 79.00\n",
      "train Epoch: 43  , Loss: 0.2466,  Accuracy: 91.90\n",
      "val Epoch: 43  , Loss: 0.8973,  Accuracy: 78.25\n",
      "train Epoch: 44  , Loss: 0.2218,  Accuracy: 92.05\n",
      "val Epoch: 44  , Loss: 0.9145,  Accuracy: 78.75\n",
      "train Epoch: 45  , Loss: 0.2019,  Accuracy: 93.85\n",
      "val Epoch: 45  , Loss: 0.8595,  Accuracy: 78.75\n",
      "train Epoch: 46  , Loss: 0.1225,  Accuracy: 95.90\n",
      "val Epoch: 46  , Loss: 0.8346,  Accuracy: 81.25\n",
      "train Epoch: 47  , Loss: 0.0977,  Accuracy: 96.65\n",
      "val Epoch: 47  , Loss: 0.9991,  Accuracy: 82.25\n",
      "train Epoch: 48  , Loss: 0.1381,  Accuracy: 95.85\n",
      "val Epoch: 48  , Loss: 0.8345,  Accuracy: 80.75\n",
      "train Epoch: 49  , Loss: 0.1110,  Accuracy: 96.50\n",
      "val Epoch: 49  , Loss: 0.9392,  Accuracy: 79.50\n",
      "train Epoch: 50  , Loss: 0.1781,  Accuracy: 94.60\n",
      "val Epoch: 50  , Loss: 0.9727,  Accuracy: 74.00\n",
      "train Epoch: 51  , Loss: 0.1906,  Accuracy: 93.35\n",
      "val Epoch: 51  , Loss: 0.7957,  Accuracy: 81.50\n",
      "train Epoch: 52  , Loss: 0.1363,  Accuracy: 95.30\n",
      "val Epoch: 52  , Loss: 1.2131,  Accuracy: 75.50\n",
      "train Epoch: 53  , Loss: 0.0976,  Accuracy: 96.15\n",
      "val Epoch: 53  , Loss: 1.0312,  Accuracy: 82.25\n",
      "train Epoch: 54  , Loss: 0.0864,  Accuracy: 97.20\n",
      "val Epoch: 54  , Loss: 0.9158,  Accuracy: 82.00\n",
      "train Epoch: 55  , Loss: 0.1701,  Accuracy: 94.05\n",
      "val Epoch: 55  , Loss: 1.3317,  Accuracy: 72.75\n",
      "train Epoch: 56  , Loss: 0.2268,  Accuracy: 92.10\n",
      "val Epoch: 56  , Loss: 1.1282,  Accuracy: 76.50\n",
      "train Epoch: 57  , Loss: 0.2262,  Accuracy: 92.55\n",
      "val Epoch: 57  , Loss: 0.9129,  Accuracy: 81.00\n",
      "train Epoch: 58  , Loss: 0.1173,  Accuracy: 96.50\n",
      "val Epoch: 58  , Loss: 1.0332,  Accuracy: 77.75\n",
      "train Epoch: 59  , Loss: 0.0870,  Accuracy: 97.05\n",
      "val Epoch: 59  , Loss: 1.1667,  Accuracy: 80.00\n",
      "train Epoch: 60  , Loss: 0.0494,  Accuracy: 98.30\n",
      "val Epoch: 60  , Loss: 1.1813,  Accuracy: 80.00\n",
      "train Epoch: 61  , Loss: 0.0717,  Accuracy: 97.90\n",
      "val Epoch: 61  , Loss: 1.2697,  Accuracy: 78.50\n",
      "train Epoch: 62  , Loss: 0.1829,  Accuracy: 94.70\n",
      "val Epoch: 62  , Loss: 0.9023,  Accuracy: 81.50\n",
      "train Epoch: 63  , Loss: 0.0916,  Accuracy: 97.05\n",
      "val Epoch: 63  , Loss: 1.0916,  Accuracy: 81.50\n",
      "train Epoch: 64  , Loss: 0.0663,  Accuracy: 97.90\n",
      "val Epoch: 64  , Loss: 1.1093,  Accuracy: 78.75\n",
      "train Epoch: 65  , Loss: 0.1131,  Accuracy: 96.40\n",
      "val Epoch: 65  , Loss: 1.0096,  Accuracy: 79.75\n",
      "train Epoch: 66  , Loss: 0.0864,  Accuracy: 97.10\n",
      "val Epoch: 66  , Loss: 1.1967,  Accuracy: 78.00\n",
      "train Epoch: 67  , Loss: 0.1368,  Accuracy: 96.00\n",
      "val Epoch: 67  , Loss: 0.9631,  Accuracy: 79.50\n",
      "train Epoch: 68  , Loss: 0.1620,  Accuracy: 95.25\n",
      "val Epoch: 68  , Loss: 1.3418,  Accuracy: 76.75\n",
      "train Epoch: 69  , Loss: 0.1401,  Accuracy: 95.15\n",
      "val Epoch: 69  , Loss: 1.0353,  Accuracy: 80.00\n",
      "train Epoch: 70  , Loss: 0.1291,  Accuracy: 95.75\n",
      "val Epoch: 70  , Loss: 1.0832,  Accuracy: 77.75\n",
      "train Epoch: 71  , Loss: 0.1104,  Accuracy: 96.70\n",
      "val Epoch: 71  , Loss: 1.0316,  Accuracy: 81.75\n",
      "train Epoch: 72  , Loss: 0.1280,  Accuracy: 95.70\n",
      "val Epoch: 72  , Loss: 1.2033,  Accuracy: 77.00\n",
      "train Epoch: 73  , Loss: 0.1080,  Accuracy: 96.75\n",
      "val Epoch: 73  , Loss: 1.0605,  Accuracy: 79.00\n",
      "train Epoch: 74  , Loss: 0.0546,  Accuracy: 98.65\n",
      "val Epoch: 74  , Loss: 1.2034,  Accuracy: 79.00\n",
      "train Epoch: 75  , Loss: 0.0505,  Accuracy: 98.40\n",
      "val Epoch: 75  , Loss: 1.0975,  Accuracy: 82.75\n",
      "train Epoch: 76  , Loss: 0.0662,  Accuracy: 97.95\n",
      "val Epoch: 76  , Loss: 1.0706,  Accuracy: 80.00\n",
      "train Epoch: 77  , Loss: 0.1034,  Accuracy: 96.65\n",
      "val Epoch: 77  , Loss: 1.1699,  Accuracy: 81.00\n",
      "train Epoch: 78  , Loss: 0.0738,  Accuracy: 97.80\n",
      "val Epoch: 78  , Loss: 0.9166,  Accuracy: 84.00\n",
      "train Epoch: 79  , Loss: 0.0290,  Accuracy: 99.15\n",
      "val Epoch: 79  , Loss: 1.1956,  Accuracy: 80.50\n",
      "train Epoch: 80  , Loss: 0.0425,  Accuracy: 98.65\n",
      "val Epoch: 80  , Loss: 1.1848,  Accuracy: 80.50\n",
      "train Epoch: 81  , Loss: 0.1293,  Accuracy: 95.90\n",
      "val Epoch: 81  , Loss: 1.1510,  Accuracy: 78.75\n",
      "train Epoch: 82  , Loss: 0.1135,  Accuracy: 96.20\n",
      "val Epoch: 82  , Loss: 1.0048,  Accuracy: 78.75\n",
      "train Epoch: 83  , Loss: 0.0731,  Accuracy: 97.60\n",
      "val Epoch: 83  , Loss: 1.1163,  Accuracy: 77.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 84  , Loss: 0.1277,  Accuracy: 96.35\n",
      "val Epoch: 84  , Loss: 1.1245,  Accuracy: 77.75\n",
      "train Epoch: 85  , Loss: 0.1706,  Accuracy: 95.20\n",
      "val Epoch: 85  , Loss: 1.0806,  Accuracy: 78.50\n",
      "train Epoch: 86  , Loss: 0.1323,  Accuracy: 96.15\n",
      "val Epoch: 86  , Loss: 1.0247,  Accuracy: 80.25\n",
      "train Epoch: 87  , Loss: 0.0698,  Accuracy: 98.00\n",
      "val Epoch: 87  , Loss: 1.0525,  Accuracy: 81.50\n",
      "train Epoch: 88  , Loss: 0.0437,  Accuracy: 98.25\n",
      "val Epoch: 88  , Loss: 1.0102,  Accuracy: 80.50\n",
      "train Epoch: 89  , Loss: 0.0345,  Accuracy: 99.05\n",
      "val Epoch: 89  , Loss: 1.3858,  Accuracy: 79.50\n",
      "train Epoch: 90  , Loss: 0.1931,  Accuracy: 93.50\n",
      "val Epoch: 90  , Loss: 1.2580,  Accuracy: 72.50\n",
      "train Epoch: 91  , Loss: 0.1206,  Accuracy: 96.45\n",
      "val Epoch: 91  , Loss: 0.9455,  Accuracy: 80.75\n",
      "train Epoch: 92  , Loss: 0.0415,  Accuracy: 98.45\n",
      "val Epoch: 92  , Loss: 1.0913,  Accuracy: 78.25\n",
      "train Epoch: 93  , Loss: 0.0304,  Accuracy: 99.00\n",
      "val Epoch: 93  , Loss: 1.0908,  Accuracy: 82.00\n",
      "train Epoch: 94  , Loss: 0.0181,  Accuracy: 99.35\n",
      "val Epoch: 94  , Loss: 1.2168,  Accuracy: 79.50\n",
      "train Epoch: 95  , Loss: 0.0177,  Accuracy: 99.35\n",
      "val Epoch: 95  , Loss: 1.2259,  Accuracy: 78.00\n",
      "train Epoch: 96  , Loss: 0.0406,  Accuracy: 98.85\n",
      "val Epoch: 96  , Loss: 1.1940,  Accuracy: 79.75\n",
      "train Epoch: 97  , Loss: 0.0738,  Accuracy: 98.00\n",
      "val Epoch: 97  , Loss: 1.1492,  Accuracy: 80.50\n",
      "train Epoch: 98  , Loss: 0.0633,  Accuracy: 98.00\n",
      "val Epoch: 98  , Loss: 1.5070,  Accuracy: 74.50\n",
      "train Epoch: 99  , Loss: 0.1626,  Accuracy: 95.00\n",
      "val Epoch: 99  , Loss: 1.1513,  Accuracy: 78.25\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    " \n",
    "    return acc.value()[0], meter_loss.value()[0]\n",
    "\n",
    "num_epochs = 100\n",
    "evaluate_every_epoch = 1\n",
    "for e in range(num_epochs):\n",
    "    acc, loss = run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    trainModel_accuracy.append(acc)\n",
    "    trainModel_loss.append(loss)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        acc, loss = run_epoch(valLD, model, criterion, e, False, None)\n",
    "        valModel_accuracy.append(acc)\n",
    "        valModel_loss.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        # Project Layer\n",
    "        self.project_layer = nn.Linear(75, 200)\n",
    "        self.project_layer_2 = nn.Linear(200, 300)\n",
    "        # Recurrent Layer\n",
    "        self.recurrent_layer = nn.LSTM(300, 400, batch_first = True)\n",
    "        self.recurrent_layer_2 = nn.LSTM(400, 500, batch_first = True)\n",
    "        self.recurrent_layer_3 = nn.LSTM(500, 500, batch_first = True)\n",
    "        # Classify Layer\n",
    "        self.classify_layer = nn.Linear(500, 300)\n",
    "        self.classify_layer_2 = nn.Linear(300, 100)\n",
    "        self.classify_layer_3 = nn.Linear(100, 10)\n",
    "        # Regularization Layer\n",
    "        self.regularization = nn.Dropout(0.2)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.02, inplace=True)\n",
    "\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs = self.project_layer(input)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer_2(rnn_outputs))\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs = self.activation(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_2(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs = self.activation(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_3(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs = self.activation(rnn_outputs)\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        logits = self.regularization(logits)\n",
    "        rnn_outputs = self.activation(logits)\n",
    "        logits = self.classify_layer_2(rnn_outputs) \n",
    "        logits = self.regularization(logits)\n",
    "        rnn_outputs = self.activation(logits)\n",
    "        logits = self.classify_layer_3(rnn_outputs)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.3051,  Accuracy: 9.80\n",
      "val Epoch: 0  , Loss: 2.3041,  Accuracy: 9.50\n",
      "train Epoch: 1  , Loss: 2.2655,  Accuracy: 14.90\n",
      "val Epoch: 1  , Loss: 2.1050,  Accuracy: 19.50\n",
      "train Epoch: 2  , Loss: 1.9032,  Accuracy: 26.50\n",
      "val Epoch: 2  , Loss: 1.9188,  Accuracy: 26.50\n",
      "train Epoch: 3  , Loss: 1.7017,  Accuracy: 33.45\n",
      "val Epoch: 3  , Loss: 1.6768,  Accuracy: 31.25\n",
      "train Epoch: 4  , Loss: 1.6460,  Accuracy: 35.80\n",
      "val Epoch: 4  , Loss: 1.7000,  Accuracy: 32.00\n",
      "train Epoch: 5  , Loss: 1.5158,  Accuracy: 40.45\n",
      "val Epoch: 5  , Loss: 1.2596,  Accuracy: 46.75\n",
      "train Epoch: 6  , Loss: 1.3569,  Accuracy: 46.20\n",
      "val Epoch: 6  , Loss: 1.2313,  Accuracy: 46.50\n",
      "train Epoch: 7  , Loss: 1.2302,  Accuracy: 50.65\n",
      "val Epoch: 7  , Loss: 1.3036,  Accuracy: 49.00\n",
      "train Epoch: 8  , Loss: 1.1822,  Accuracy: 53.70\n",
      "val Epoch: 8  , Loss: 1.2062,  Accuracy: 53.75\n",
      "train Epoch: 9  , Loss: 1.1794,  Accuracy: 52.70\n",
      "val Epoch: 9  , Loss: 1.1318,  Accuracy: 55.75\n",
      "train Epoch: 10  , Loss: 1.1067,  Accuracy: 55.90\n",
      "val Epoch: 10  , Loss: 1.0040,  Accuracy: 61.25\n",
      "train Epoch: 11  , Loss: 1.0516,  Accuracy: 57.95\n",
      "val Epoch: 11  , Loss: 1.1014,  Accuracy: 58.75\n",
      "train Epoch: 12  , Loss: 1.1205,  Accuracy: 56.35\n",
      "val Epoch: 12  , Loss: 1.0274,  Accuracy: 60.00\n",
      "train Epoch: 13  , Loss: 1.0124,  Accuracy: 60.50\n",
      "val Epoch: 13  , Loss: 0.9825,  Accuracy: 62.75\n",
      "train Epoch: 14  , Loss: 0.9433,  Accuracy: 62.50\n",
      "val Epoch: 14  , Loss: 1.0600,  Accuracy: 64.00\n",
      "train Epoch: 15  , Loss: 0.9408,  Accuracy: 63.60\n",
      "val Epoch: 15  , Loss: 0.8831,  Accuracy: 68.25\n",
      "train Epoch: 16  , Loss: 0.8755,  Accuracy: 66.80\n",
      "val Epoch: 16  , Loss: 1.1148,  Accuracy: 58.50\n",
      "train Epoch: 17  , Loss: 0.9344,  Accuracy: 65.80\n",
      "val Epoch: 17  , Loss: 0.9532,  Accuracy: 67.00\n",
      "train Epoch: 18  , Loss: 0.8332,  Accuracy: 69.60\n",
      "val Epoch: 18  , Loss: 0.8749,  Accuracy: 70.00\n",
      "train Epoch: 19  , Loss: 0.8319,  Accuracy: 69.90\n",
      "val Epoch: 19  , Loss: 0.8923,  Accuracy: 65.25\n",
      "train Epoch: 20  , Loss: 0.8019,  Accuracy: 71.05\n",
      "val Epoch: 20  , Loss: 0.8501,  Accuracy: 71.25\n",
      "train Epoch: 21  , Loss: 0.7519,  Accuracy: 72.30\n",
      "val Epoch: 21  , Loss: 0.9291,  Accuracy: 69.25\n",
      "train Epoch: 22  , Loss: 0.7749,  Accuracy: 71.45\n",
      "val Epoch: 22  , Loss: 0.8737,  Accuracy: 69.25\n",
      "train Epoch: 23  , Loss: 0.7009,  Accuracy: 74.65\n",
      "val Epoch: 23  , Loss: 0.9151,  Accuracy: 71.75\n",
      "train Epoch: 24  , Loss: 0.7055,  Accuracy: 74.50\n",
      "val Epoch: 24  , Loss: 0.8921,  Accuracy: 70.75\n",
      "train Epoch: 25  , Loss: 0.6861,  Accuracy: 76.10\n",
      "val Epoch: 25  , Loss: 0.9252,  Accuracy: 70.25\n",
      "train Epoch: 26  , Loss: 0.6918,  Accuracy: 75.05\n",
      "val Epoch: 26  , Loss: 0.7570,  Accuracy: 76.50\n",
      "train Epoch: 27  , Loss: 0.5672,  Accuracy: 79.80\n",
      "val Epoch: 27  , Loss: 0.6917,  Accuracy: 78.00\n",
      "train Epoch: 28  , Loss: 0.6774,  Accuracy: 76.50\n",
      "val Epoch: 28  , Loss: 0.8793,  Accuracy: 73.00\n",
      "train Epoch: 29  , Loss: 0.6580,  Accuracy: 76.35\n",
      "val Epoch: 29  , Loss: 0.8598,  Accuracy: 75.75\n",
      "train Epoch: 30  , Loss: 0.6108,  Accuracy: 78.70\n",
      "val Epoch: 30  , Loss: 0.7365,  Accuracy: 76.25\n",
      "train Epoch: 31  , Loss: 0.5722,  Accuracy: 80.35\n",
      "val Epoch: 31  , Loss: 0.8110,  Accuracy: 76.50\n",
      "train Epoch: 32  , Loss: 0.4811,  Accuracy: 83.75\n",
      "val Epoch: 32  , Loss: 0.7641,  Accuracy: 78.50\n",
      "train Epoch: 33  , Loss: 0.5244,  Accuracy: 81.90\n",
      "val Epoch: 33  , Loss: 0.8754,  Accuracy: 72.50\n",
      "train Epoch: 34  , Loss: 0.5358,  Accuracy: 80.95\n",
      "val Epoch: 34  , Loss: 0.8668,  Accuracy: 75.00\n",
      "train Epoch: 35  , Loss: 0.5462,  Accuracy: 80.65\n",
      "val Epoch: 35  , Loss: 0.7345,  Accuracy: 79.00\n",
      "train Epoch: 36  , Loss: 0.4723,  Accuracy: 82.95\n",
      "val Epoch: 36  , Loss: 0.8597,  Accuracy: 75.75\n",
      "train Epoch: 37  , Loss: 0.4366,  Accuracy: 84.00\n",
      "val Epoch: 37  , Loss: 0.8549,  Accuracy: 77.00\n",
      "train Epoch: 38  , Loss: 0.4208,  Accuracy: 84.60\n",
      "val Epoch: 38  , Loss: 0.6930,  Accuracy: 79.50\n",
      "train Epoch: 39  , Loss: 0.3963,  Accuracy: 86.05\n",
      "val Epoch: 39  , Loss: 0.7785,  Accuracy: 78.25\n",
      "train Epoch: 40  , Loss: 0.3846,  Accuracy: 86.65\n",
      "val Epoch: 40  , Loss: 0.7709,  Accuracy: 77.25\n",
      "train Epoch: 41  , Loss: 0.3859,  Accuracy: 87.25\n",
      "val Epoch: 41  , Loss: 0.7780,  Accuracy: 77.25\n",
      "train Epoch: 42  , Loss: 0.4263,  Accuracy: 84.45\n",
      "val Epoch: 42  , Loss: 0.7981,  Accuracy: 77.25\n",
      "train Epoch: 43  , Loss: 0.4085,  Accuracy: 86.05\n",
      "val Epoch: 43  , Loss: 0.7740,  Accuracy: 78.00\n",
      "train Epoch: 44  , Loss: 0.3819,  Accuracy: 87.60\n",
      "val Epoch: 44  , Loss: 0.8187,  Accuracy: 80.00\n",
      "train Epoch: 45  , Loss: 0.3827,  Accuracy: 86.60\n",
      "val Epoch: 45  , Loss: 0.8330,  Accuracy: 75.25\n",
      "train Epoch: 46  , Loss: 0.4306,  Accuracy: 85.00\n",
      "val Epoch: 46  , Loss: 0.8668,  Accuracy: 76.75\n",
      "train Epoch: 47  , Loss: 0.4246,  Accuracy: 86.05\n",
      "val Epoch: 47  , Loss: 0.7839,  Accuracy: 77.75\n",
      "train Epoch: 48  , Loss: 0.3611,  Accuracy: 86.30\n",
      "val Epoch: 48  , Loss: 0.8031,  Accuracy: 80.00\n",
      "train Epoch: 49  , Loss: 0.3377,  Accuracy: 87.60\n",
      "val Epoch: 49  , Loss: 0.8478,  Accuracy: 77.50\n",
      "train Epoch: 50  , Loss: 0.3787,  Accuracy: 87.10\n",
      "val Epoch: 50  , Loss: 0.8476,  Accuracy: 76.50\n",
      "train Epoch: 51  , Loss: 0.3687,  Accuracy: 87.30\n",
      "val Epoch: 51  , Loss: 0.8265,  Accuracy: 79.25\n",
      "train Epoch: 52  , Loss: 0.3210,  Accuracy: 88.90\n",
      "val Epoch: 52  , Loss: 0.8108,  Accuracy: 78.25\n",
      "train Epoch: 53  , Loss: 0.2569,  Accuracy: 90.80\n",
      "val Epoch: 53  , Loss: 0.8645,  Accuracy: 77.50\n",
      "train Epoch: 54  , Loss: 0.2832,  Accuracy: 90.05\n",
      "val Epoch: 54  , Loss: 0.7582,  Accuracy: 79.75\n",
      "train Epoch: 55  , Loss: 0.2784,  Accuracy: 89.85\n",
      "val Epoch: 55  , Loss: 0.7972,  Accuracy: 80.00\n",
      "train Epoch: 56  , Loss: 0.2516,  Accuracy: 91.05\n",
      "val Epoch: 56  , Loss: 0.9780,  Accuracy: 77.50\n",
      "train Epoch: 57  , Loss: 0.2265,  Accuracy: 92.55\n",
      "val Epoch: 57  , Loss: 0.8411,  Accuracy: 81.75\n",
      "train Epoch: 58  , Loss: 0.2904,  Accuracy: 90.00\n",
      "val Epoch: 58  , Loss: 0.9671,  Accuracy: 76.00\n",
      "train Epoch: 59  , Loss: 0.3299,  Accuracy: 88.40\n",
      "val Epoch: 59  , Loss: 0.7810,  Accuracy: 81.00\n",
      "train Epoch: 60  , Loss: 0.2657,  Accuracy: 90.50\n",
      "val Epoch: 60  , Loss: 0.8521,  Accuracy: 78.25\n",
      "train Epoch: 61  , Loss: 0.2148,  Accuracy: 92.90\n",
      "val Epoch: 61  , Loss: 1.1338,  Accuracy: 73.00\n",
      "train Epoch: 62  , Loss: 0.2995,  Accuracy: 89.60\n",
      "val Epoch: 62  , Loss: 0.8093,  Accuracy: 80.00\n",
      "train Epoch: 63  , Loss: 0.1961,  Accuracy: 92.20\n",
      "val Epoch: 63  , Loss: 0.9081,  Accuracy: 81.00\n",
      "train Epoch: 64  , Loss: 0.1815,  Accuracy: 93.85\n",
      "val Epoch: 64  , Loss: 0.9929,  Accuracy: 81.75\n",
      "train Epoch: 65  , Loss: 0.3218,  Accuracy: 90.65\n",
      "val Epoch: 65  , Loss: 0.8600,  Accuracy: 78.25\n",
      "train Epoch: 66  , Loss: 0.2385,  Accuracy: 91.80\n",
      "val Epoch: 66  , Loss: 0.8544,  Accuracy: 80.50\n",
      "train Epoch: 67  , Loss: 0.1414,  Accuracy: 95.25\n",
      "val Epoch: 67  , Loss: 1.1030,  Accuracy: 75.75\n",
      "train Epoch: 68  , Loss: 0.1850,  Accuracy: 94.05\n",
      "val Epoch: 68  , Loss: 0.9614,  Accuracy: 80.50\n",
      "train Epoch: 69  , Loss: 0.1609,  Accuracy: 93.90\n",
      "val Epoch: 69  , Loss: 0.9604,  Accuracy: 79.00\n",
      "train Epoch: 70  , Loss: 0.1941,  Accuracy: 93.75\n",
      "val Epoch: 70  , Loss: 0.9159,  Accuracy: 77.75\n",
      "train Epoch: 71  , Loss: 0.1449,  Accuracy: 95.15\n",
      "val Epoch: 71  , Loss: 0.8818,  Accuracy: 80.25\n",
      "train Epoch: 72  , Loss: 0.1245,  Accuracy: 96.05\n",
      "val Epoch: 72  , Loss: 1.0822,  Accuracy: 79.25\n",
      "train Epoch: 73  , Loss: 0.1580,  Accuracy: 94.70\n",
      "val Epoch: 73  , Loss: 0.9326,  Accuracy: 81.00\n",
      "train Epoch: 74  , Loss: 0.2534,  Accuracy: 91.90\n",
      "val Epoch: 74  , Loss: 0.9880,  Accuracy: 74.00\n",
      "train Epoch: 75  , Loss: 0.2529,  Accuracy: 91.85\n",
      "val Epoch: 75  , Loss: 0.9162,  Accuracy: 78.75\n",
      "train Epoch: 76  , Loss: 0.1672,  Accuracy: 94.05\n",
      "val Epoch: 76  , Loss: 0.9241,  Accuracy: 80.75\n",
      "train Epoch: 77  , Loss: 0.1585,  Accuracy: 94.30\n",
      "val Epoch: 77  , Loss: 0.8564,  Accuracy: 81.25\n",
      "train Epoch: 78  , Loss: 0.1681,  Accuracy: 94.20\n",
      "val Epoch: 78  , Loss: 1.0144,  Accuracy: 79.50\n",
      "train Epoch: 79  , Loss: 0.1860,  Accuracy: 94.15\n",
      "val Epoch: 79  , Loss: 0.9890,  Accuracy: 78.75\n",
      "train Epoch: 80  , Loss: 0.1338,  Accuracy: 95.50\n",
      "val Epoch: 80  , Loss: 1.0102,  Accuracy: 80.00\n",
      "train Epoch: 81  , Loss: 0.0813,  Accuracy: 97.40\n",
      "val Epoch: 81  , Loss: 1.0590,  Accuracy: 80.25\n",
      "train Epoch: 82  , Loss: 0.2181,  Accuracy: 92.75\n",
      "val Epoch: 82  , Loss: 0.9173,  Accuracy: 80.25\n",
      "train Epoch: 83  , Loss: 0.1300,  Accuracy: 95.40\n",
      "val Epoch: 83  , Loss: 1.0638,  Accuracy: 78.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 84  , Loss: 0.1406,  Accuracy: 95.35\n",
      "val Epoch: 84  , Loss: 1.1289,  Accuracy: 79.25\n",
      "train Epoch: 85  , Loss: 0.1052,  Accuracy: 96.65\n",
      "val Epoch: 85  , Loss: 1.0489,  Accuracy: 80.25\n",
      "train Epoch: 86  , Loss: 0.0946,  Accuracy: 96.65\n",
      "val Epoch: 86  , Loss: 1.0629,  Accuracy: 79.50\n",
      "train Epoch: 87  , Loss: 0.1360,  Accuracy: 95.95\n",
      "val Epoch: 87  , Loss: 0.9836,  Accuracy: 78.75\n",
      "train Epoch: 88  , Loss: 0.1070,  Accuracy: 96.85\n",
      "val Epoch: 88  , Loss: 0.9946,  Accuracy: 79.75\n",
      "train Epoch: 89  , Loss: 0.1272,  Accuracy: 95.65\n",
      "val Epoch: 89  , Loss: 1.0158,  Accuracy: 79.00\n",
      "train Epoch: 90  , Loss: 0.1461,  Accuracy: 96.15\n",
      "val Epoch: 90  , Loss: 0.9520,  Accuracy: 80.50\n",
      "train Epoch: 91  , Loss: 0.1195,  Accuracy: 95.45\n",
      "val Epoch: 91  , Loss: 1.1784,  Accuracy: 79.75\n",
      "train Epoch: 92  , Loss: 0.0741,  Accuracy: 97.65\n",
      "val Epoch: 92  , Loss: 1.1243,  Accuracy: 81.00\n",
      "train Epoch: 93  , Loss: 0.0561,  Accuracy: 98.40\n",
      "val Epoch: 93  , Loss: 1.3301,  Accuracy: 78.75\n",
      "train Epoch: 94  , Loss: 0.0837,  Accuracy: 97.65\n",
      "val Epoch: 94  , Loss: 1.2735,  Accuracy: 78.50\n",
      "train Epoch: 95  , Loss: 0.1457,  Accuracy: 94.90\n",
      "val Epoch: 95  , Loss: 1.0903,  Accuracy: 80.75\n",
      "train Epoch: 96  , Loss: 0.1190,  Accuracy: 96.15\n",
      "val Epoch: 96  , Loss: 1.1196,  Accuracy: 79.50\n",
      "train Epoch: 97  , Loss: 0.0745,  Accuracy: 97.50\n",
      "val Epoch: 97  , Loss: 1.2891,  Accuracy: 79.00\n",
      "train Epoch: 98  , Loss: 0.1193,  Accuracy: 96.15\n",
      "val Epoch: 98  , Loss: 1.1348,  Accuracy: 77.00\n",
      "train Epoch: 99  , Loss: 0.0998,  Accuracy: 96.45\n",
      "val Epoch: 99  , Loss: 1.0563,  Accuracy: 80.00\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    " \n",
    "    return acc.value()[0], meter_loss.value()[0]\n",
    "\n",
    "num_epochs = 100\n",
    "evaluate_every_epoch = 1\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence classification model\n",
    "class SequenceClassify(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassify, self).__init__()\n",
    "        \n",
    "        # Project Layer\n",
    "        self.project_layer = nn.Linear(75, 200)\n",
    "        self.project_layer_2 = nn.Linear(200, 300)\n",
    "        self.project_layer_3 = nn.Linear(300, 400)\n",
    "        # Recurrent Layer\n",
    "        self.recurrent_layer = nn.LSTM(400, 500, batch_first = True)\n",
    "        self.recurrent_layer_2 = nn.LSTM(500, 600, batch_first = True)\n",
    "        self.recurrent_layer_3 = nn.LSTM(600, 700, batch_first = True)\n",
    "        self.recurrent_layer_4 = nn.LSTM(700, 700, batch_first = True)\n",
    "        # Classify Layer\n",
    "        self.classify_layer = nn.Linear(700, 500)\n",
    "        self.classify_layer_2 = nn.Linear(500, 300)\n",
    "        self.classify_layer_3 = nn.Linear(300, 100)\n",
    "        self.classify_layer_4 = nn.Linear(100, 10)\n",
    "        # Regularization Layer\n",
    "        self.regularization = nn.Dropout(0.1)\n",
    "\n",
    "    \n",
    "    # the size of input is [batch_size, seq_len(15), input_dim(75)]\n",
    "    # the size of logits is [batch_size, num_class]\n",
    "    def forward(self, input, h_t_1=None, c_t_1=None):\n",
    "        # the size of rnn_outputs is [batch_size, seq_len, rnn_size]\n",
    "        rnn_outputs = self.project_layer(input)\n",
    "        rnn_outputs = self.regularization(rnn_outputs) \n",
    "        rnn_outputs = self.project_layer_2(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs) \n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer(self.project_layer_3(rnn_outputs))\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_2(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs) \n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_3(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        rnn_outputs, (hn, cn) = self.recurrent_layer_4(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(rnn_outputs)\n",
    "        # classify the last step of rnn_outpus\n",
    "        # the size of logits is [batch_size, num_class]\n",
    "        logits = self.classify_layer(rnn_outputs[:,-1])\n",
    "        rnn_outputs = self.regularization(logits) \n",
    "        logits = self.classify_layer_2(rnn_outputs) \n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_3(rnn_outputs)\n",
    "        rnn_outputs = self.regularization(logits)\n",
    "        logits = self.classify_layer_4(rnn_outputs)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "model = SequenceClassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 0  , Loss: 2.3050,  Accuracy: 9.40\n",
      "val Epoch: 0  , Loss: 2.2989,  Accuracy: 15.25\n",
      "train Epoch: 1  , Loss: 2.2086,  Accuracy: 15.20\n",
      "val Epoch: 1  , Loss: 2.0046,  Accuracy: 18.00\n",
      "train Epoch: 2  , Loss: 1.9515,  Accuracy: 18.35\n",
      "val Epoch: 2  , Loss: 1.8390,  Accuracy: 25.25\n",
      "train Epoch: 3  , Loss: 1.8388,  Accuracy: 26.20\n",
      "val Epoch: 3  , Loss: 1.7247,  Accuracy: 28.75\n",
      "train Epoch: 4  , Loss: 1.7316,  Accuracy: 30.00\n",
      "val Epoch: 4  , Loss: 1.6326,  Accuracy: 33.50\n",
      "train Epoch: 5  , Loss: 1.6694,  Accuracy: 33.40\n",
      "val Epoch: 5  , Loss: 1.6443,  Accuracy: 36.50\n",
      "train Epoch: 6  , Loss: 1.6511,  Accuracy: 33.85\n",
      "val Epoch: 6  , Loss: 1.6482,  Accuracy: 36.25\n",
      "train Epoch: 7  , Loss: 1.5620,  Accuracy: 38.80\n",
      "val Epoch: 7  , Loss: 1.4421,  Accuracy: 47.00\n",
      "train Epoch: 8  , Loss: 1.5152,  Accuracy: 41.05\n",
      "val Epoch: 8  , Loss: 1.4365,  Accuracy: 44.25\n",
      "train Epoch: 9  , Loss: 1.4703,  Accuracy: 43.65\n",
      "val Epoch: 9  , Loss: 1.4267,  Accuracy: 47.00\n",
      "train Epoch: 10  , Loss: 1.3743,  Accuracy: 47.25\n",
      "val Epoch: 10  , Loss: 1.3707,  Accuracy: 49.25\n",
      "train Epoch: 11  , Loss: 1.3072,  Accuracy: 51.15\n",
      "val Epoch: 11  , Loss: 1.3839,  Accuracy: 48.25\n",
      "train Epoch: 12  , Loss: 1.2756,  Accuracy: 53.70\n",
      "val Epoch: 12  , Loss: 1.2416,  Accuracy: 57.50\n",
      "train Epoch: 13  , Loss: 1.1975,  Accuracy: 55.65\n",
      "val Epoch: 13  , Loss: 1.1346,  Accuracy: 63.00\n",
      "train Epoch: 14  , Loss: 1.1394,  Accuracy: 57.65\n",
      "val Epoch: 14  , Loss: 1.0989,  Accuracy: 59.00\n",
      "train Epoch: 15  , Loss: 1.1089,  Accuracy: 58.50\n",
      "val Epoch: 15  , Loss: 1.0954,  Accuracy: 64.00\n",
      "train Epoch: 16  , Loss: 1.0408,  Accuracy: 62.00\n",
      "val Epoch: 16  , Loss: 1.1136,  Accuracy: 62.50\n",
      "train Epoch: 17  , Loss: 0.9776,  Accuracy: 62.65\n",
      "val Epoch: 17  , Loss: 1.0256,  Accuracy: 63.00\n",
      "train Epoch: 18  , Loss: 0.9598,  Accuracy: 64.05\n",
      "val Epoch: 18  , Loss: 1.0144,  Accuracy: 62.00\n",
      "train Epoch: 19  , Loss: 0.9357,  Accuracy: 64.25\n",
      "val Epoch: 19  , Loss: 1.0532,  Accuracy: 63.75\n",
      "train Epoch: 20  , Loss: 0.9212,  Accuracy: 65.95\n",
      "val Epoch: 20  , Loss: 0.9379,  Accuracy: 70.50\n",
      "train Epoch: 21  , Loss: 0.8931,  Accuracy: 66.50\n",
      "val Epoch: 21  , Loss: 0.9103,  Accuracy: 68.75\n",
      "train Epoch: 22  , Loss: 0.9110,  Accuracy: 65.75\n",
      "val Epoch: 22  , Loss: 0.9191,  Accuracy: 69.25\n",
      "train Epoch: 23  , Loss: 0.8378,  Accuracy: 69.30\n",
      "val Epoch: 23  , Loss: 0.9110,  Accuracy: 69.00\n",
      "train Epoch: 24  , Loss: 0.8211,  Accuracy: 69.70\n",
      "val Epoch: 24  , Loss: 0.9624,  Accuracy: 67.25\n",
      "train Epoch: 25  , Loss: 0.8108,  Accuracy: 70.30\n",
      "val Epoch: 25  , Loss: 0.9229,  Accuracy: 70.00\n",
      "train Epoch: 26  , Loss: 0.7982,  Accuracy: 70.85\n",
      "val Epoch: 26  , Loss: 0.9378,  Accuracy: 68.50\n",
      "train Epoch: 27  , Loss: 0.7794,  Accuracy: 71.70\n",
      "val Epoch: 27  , Loss: 0.9732,  Accuracy: 68.75\n",
      "train Epoch: 28  , Loss: 0.7796,  Accuracy: 70.60\n",
      "val Epoch: 28  , Loss: 0.9568,  Accuracy: 70.25\n",
      "train Epoch: 29  , Loss: 0.7601,  Accuracy: 71.45\n",
      "val Epoch: 29  , Loss: 0.9149,  Accuracy: 70.50\n",
      "train Epoch: 30  , Loss: 0.7377,  Accuracy: 72.90\n",
      "val Epoch: 30  , Loss: 0.8702,  Accuracy: 73.25\n",
      "train Epoch: 31  , Loss: 0.6942,  Accuracy: 73.75\n",
      "val Epoch: 31  , Loss: 0.9467,  Accuracy: 67.50\n",
      "train Epoch: 32  , Loss: 0.7000,  Accuracy: 73.80\n",
      "val Epoch: 32  , Loss: 0.9719,  Accuracy: 67.75\n",
      "train Epoch: 33  , Loss: 0.6937,  Accuracy: 74.55\n",
      "val Epoch: 33  , Loss: 0.8403,  Accuracy: 73.25\n",
      "train Epoch: 34  , Loss: 0.6674,  Accuracy: 75.50\n",
      "val Epoch: 34  , Loss: 0.9148,  Accuracy: 68.50\n",
      "train Epoch: 35  , Loss: 0.6654,  Accuracy: 76.20\n",
      "val Epoch: 35  , Loss: 0.8742,  Accuracy: 71.50\n",
      "train Epoch: 36  , Loss: 0.6260,  Accuracy: 77.90\n",
      "val Epoch: 36  , Loss: 0.9158,  Accuracy: 72.25\n",
      "train Epoch: 37  , Loss: 0.6498,  Accuracy: 76.85\n",
      "val Epoch: 37  , Loss: 0.8377,  Accuracy: 71.25\n",
      "train Epoch: 38  , Loss: 0.5874,  Accuracy: 79.45\n",
      "val Epoch: 38  , Loss: 0.8293,  Accuracy: 75.50\n",
      "train Epoch: 39  , Loss: 0.5575,  Accuracy: 80.15\n",
      "val Epoch: 39  , Loss: 0.8448,  Accuracy: 75.75\n",
      "train Epoch: 40  , Loss: 0.5329,  Accuracy: 80.25\n",
      "val Epoch: 40  , Loss: 0.8312,  Accuracy: 75.00\n",
      "train Epoch: 41  , Loss: 0.5269,  Accuracy: 80.35\n",
      "val Epoch: 41  , Loss: 0.8423,  Accuracy: 75.50\n",
      "train Epoch: 42  , Loss: 0.5017,  Accuracy: 81.55\n",
      "val Epoch: 42  , Loss: 0.8909,  Accuracy: 74.25\n",
      "train Epoch: 43  , Loss: 0.4914,  Accuracy: 81.55\n",
      "val Epoch: 43  , Loss: 0.9016,  Accuracy: 73.75\n",
      "train Epoch: 44  , Loss: 0.4642,  Accuracy: 83.40\n",
      "val Epoch: 44  , Loss: 0.8405,  Accuracy: 74.00\n",
      "train Epoch: 45  , Loss: 0.4545,  Accuracy: 83.85\n",
      "val Epoch: 45  , Loss: 0.8523,  Accuracy: 76.50\n",
      "train Epoch: 46  , Loss: 0.4646,  Accuracy: 83.20\n",
      "val Epoch: 46  , Loss: 0.8288,  Accuracy: 75.75\n",
      "train Epoch: 47  , Loss: 0.4296,  Accuracy: 84.25\n",
      "val Epoch: 47  , Loss: 0.8873,  Accuracy: 74.00\n",
      "train Epoch: 48  , Loss: 0.4254,  Accuracy: 84.10\n",
      "val Epoch: 48  , Loss: 0.9809,  Accuracy: 74.25\n",
      "train Epoch: 49  , Loss: 0.4254,  Accuracy: 83.70\n",
      "val Epoch: 49  , Loss: 0.9305,  Accuracy: 75.75\n",
      "train Epoch: 50  , Loss: 0.3739,  Accuracy: 85.80\n",
      "val Epoch: 50  , Loss: 0.8813,  Accuracy: 75.50\n",
      "train Epoch: 51  , Loss: 0.3992,  Accuracy: 85.30\n",
      "val Epoch: 51  , Loss: 1.1046,  Accuracy: 69.25\n",
      "train Epoch: 52  , Loss: 0.3849,  Accuracy: 85.60\n",
      "val Epoch: 52  , Loss: 0.9599,  Accuracy: 73.75\n",
      "train Epoch: 53  , Loss: 0.3612,  Accuracy: 86.70\n",
      "val Epoch: 53  , Loss: 0.9440,  Accuracy: 76.25\n",
      "train Epoch: 54  , Loss: 0.3509,  Accuracy: 87.25\n",
      "val Epoch: 54  , Loss: 0.8982,  Accuracy: 77.00\n",
      "train Epoch: 55  , Loss: 0.3421,  Accuracy: 87.30\n",
      "val Epoch: 55  , Loss: 0.9971,  Accuracy: 74.00\n",
      "train Epoch: 56  , Loss: 0.3708,  Accuracy: 85.40\n",
      "val Epoch: 56  , Loss: 0.9011,  Accuracy: 77.00\n",
      "train Epoch: 57  , Loss: 0.3269,  Accuracy: 87.40\n",
      "val Epoch: 57  , Loss: 0.8351,  Accuracy: 77.50\n",
      "train Epoch: 58  , Loss: 0.2736,  Accuracy: 90.00\n",
      "val Epoch: 58  , Loss: 0.9902,  Accuracy: 78.25\n",
      "train Epoch: 59  , Loss: 0.2967,  Accuracy: 89.20\n",
      "val Epoch: 59  , Loss: 1.0349,  Accuracy: 76.00\n",
      "train Epoch: 60  , Loss: 0.2878,  Accuracy: 89.60\n",
      "val Epoch: 60  , Loss: 0.9322,  Accuracy: 77.75\n",
      "train Epoch: 61  , Loss: 0.3162,  Accuracy: 87.30\n",
      "val Epoch: 61  , Loss: 1.0081,  Accuracy: 76.75\n",
      "train Epoch: 62  , Loss: 0.2659,  Accuracy: 90.05\n",
      "val Epoch: 62  , Loss: 0.9100,  Accuracy: 76.00\n",
      "train Epoch: 63  , Loss: 0.2372,  Accuracy: 91.00\n",
      "val Epoch: 63  , Loss: 1.0402,  Accuracy: 75.75\n",
      "train Epoch: 64  , Loss: 0.2160,  Accuracy: 92.25\n",
      "val Epoch: 64  , Loss: 0.9763,  Accuracy: 78.50\n",
      "train Epoch: 65  , Loss: 0.2045,  Accuracy: 92.45\n",
      "val Epoch: 65  , Loss: 1.0285,  Accuracy: 77.00\n",
      "train Epoch: 66  , Loss: 0.2170,  Accuracy: 91.60\n",
      "val Epoch: 66  , Loss: 1.0276,  Accuracy: 76.25\n",
      "train Epoch: 67  , Loss: 0.2606,  Accuracy: 90.45\n",
      "val Epoch: 67  , Loss: 1.1171,  Accuracy: 75.50\n",
      "train Epoch: 68  , Loss: 0.2597,  Accuracy: 90.40\n",
      "val Epoch: 68  , Loss: 1.0967,  Accuracy: 77.00\n",
      "train Epoch: 69  , Loss: 0.2066,  Accuracy: 92.35\n",
      "val Epoch: 69  , Loss: 1.0979,  Accuracy: 76.50\n",
      "train Epoch: 70  , Loss: 0.1871,  Accuracy: 93.15\n",
      "val Epoch: 70  , Loss: 1.0563,  Accuracy: 77.00\n",
      "train Epoch: 71  , Loss: 0.1477,  Accuracy: 94.50\n",
      "val Epoch: 71  , Loss: 1.0388,  Accuracy: 78.50\n",
      "train Epoch: 72  , Loss: 0.1519,  Accuracy: 94.50\n",
      "val Epoch: 72  , Loss: 1.1598,  Accuracy: 77.50\n",
      "train Epoch: 73  , Loss: 0.1423,  Accuracy: 94.25\n",
      "val Epoch: 73  , Loss: 1.2033,  Accuracy: 78.00\n",
      "train Epoch: 74  , Loss: 0.1763,  Accuracy: 92.85\n",
      "val Epoch: 74  , Loss: 1.2048,  Accuracy: 77.25\n",
      "train Epoch: 75  , Loss: 0.1276,  Accuracy: 95.50\n",
      "val Epoch: 75  , Loss: 1.1416,  Accuracy: 76.25\n",
      "train Epoch: 76  , Loss: 0.1283,  Accuracy: 95.35\n",
      "val Epoch: 76  , Loss: 1.2786,  Accuracy: 75.25\n",
      "train Epoch: 77  , Loss: 0.1297,  Accuracy: 95.35\n",
      "val Epoch: 77  , Loss: 1.2302,  Accuracy: 78.00\n",
      "train Epoch: 78  , Loss: 0.1164,  Accuracy: 95.80\n",
      "val Epoch: 78  , Loss: 1.3032,  Accuracy: 78.25\n",
      "train Epoch: 79  , Loss: 0.1409,  Accuracy: 94.95\n",
      "val Epoch: 79  , Loss: 1.3833,  Accuracy: 73.25\n",
      "train Epoch: 80  , Loss: 0.1436,  Accuracy: 94.55\n",
      "val Epoch: 80  , Loss: 1.4063,  Accuracy: 75.00\n",
      "train Epoch: 81  , Loss: 0.1292,  Accuracy: 95.60\n",
      "val Epoch: 81  , Loss: 1.2641,  Accuracy: 77.50\n",
      "train Epoch: 82  , Loss: 0.0897,  Accuracy: 97.10\n",
      "val Epoch: 82  , Loss: 1.5700,  Accuracy: 74.25\n",
      "train Epoch: 83  , Loss: 0.1359,  Accuracy: 94.85\n",
      "val Epoch: 83  , Loss: 1.4569,  Accuracy: 75.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 84  , Loss: 0.0969,  Accuracy: 96.30\n",
      "val Epoch: 84  , Loss: 1.3568,  Accuracy: 76.00\n",
      "train Epoch: 85  , Loss: 0.0924,  Accuracy: 96.80\n",
      "val Epoch: 85  , Loss: 1.2797,  Accuracy: 77.25\n",
      "train Epoch: 86  , Loss: 0.0916,  Accuracy: 96.45\n",
      "val Epoch: 86  , Loss: 1.2871,  Accuracy: 75.75\n",
      "train Epoch: 87  , Loss: 0.0961,  Accuracy: 96.65\n",
      "val Epoch: 87  , Loss: 1.3981,  Accuracy: 75.75\n",
      "train Epoch: 88  , Loss: 0.1020,  Accuracy: 96.80\n",
      "val Epoch: 88  , Loss: 1.2578,  Accuracy: 77.50\n",
      "train Epoch: 89  , Loss: 0.0662,  Accuracy: 97.75\n",
      "val Epoch: 89  , Loss: 1.3475,  Accuracy: 76.50\n",
      "train Epoch: 90  , Loss: 0.0657,  Accuracy: 97.55\n",
      "val Epoch: 90  , Loss: 1.4610,  Accuracy: 75.25\n",
      "train Epoch: 91  , Loss: 0.0472,  Accuracy: 98.35\n",
      "val Epoch: 91  , Loss: 1.5518,  Accuracy: 77.75\n",
      "train Epoch: 92  , Loss: 0.0686,  Accuracy: 97.80\n",
      "val Epoch: 92  , Loss: 1.4376,  Accuracy: 78.50\n",
      "train Epoch: 93  , Loss: 0.0994,  Accuracy: 96.75\n",
      "val Epoch: 93  , Loss: 1.6326,  Accuracy: 78.25\n",
      "train Epoch: 94  , Loss: 0.1105,  Accuracy: 96.10\n",
      "val Epoch: 94  , Loss: 1.3427,  Accuracy: 77.75\n",
      "train Epoch: 95  , Loss: 0.1091,  Accuracy: 96.40\n",
      "val Epoch: 95  , Loss: 1.4567,  Accuracy: 77.50\n",
      "train Epoch: 96  , Loss: 0.0952,  Accuracy: 96.70\n",
      "val Epoch: 96  , Loss: 1.4169,  Accuracy: 76.25\n",
      "train Epoch: 97  , Loss: 0.0792,  Accuracy: 97.35\n",
      "val Epoch: 97  , Loss: 1.4185,  Accuracy: 75.00\n",
      "train Epoch: 98  , Loss: 0.1102,  Accuracy: 96.40\n",
      "val Epoch: 98  , Loss: 1.4684,  Accuracy: 75.00\n",
      "train Epoch: 99  , Loss: 0.0737,  Accuracy: 97.30\n",
      "val Epoch: 99  , Loss: 1.4760,  Accuracy: 76.50\n"
     ]
    }
   ],
   "source": [
    "# run the model for one epoch\n",
    "# can be used for both training or validation model\n",
    "def run_epoch(data_loader, model, criterion, epoch, is_training, optimizer=None):\n",
    "    if is_training:\n",
    "        model.train()\n",
    "        logger_prefix = 'train'\n",
    "    else:\n",
    "        model.eval()\n",
    "        logger_prefix = 'val'\n",
    "\n",
    "    confusion_matrix = tnt.meter.ConfusionMeter(num_class)\n",
    "    acc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "    meter_loss = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        label = sample['label']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        input_label_var = Variable(label).type(LongTensor)\n",
    "\n",
    "        # compute output\n",
    "        # output_logits: [batch_size, num_class]\n",
    "        output_logits = model(input_sequence_var)\n",
    "        loss = criterion(output_logits, input_label_var)\n",
    "\n",
    "        if is_training:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter_loss.add(loss.data[0])\n",
    "        acc.add(output_logits.data, input_label_var.data)\n",
    "        confusion_matrix.add(output_logits.data, input_label_var.data)\n",
    "\n",
    "\n",
    "    print('%s Epoch: %d  , Loss: %.4f,  Accuracy: %.2f'%(logger_prefix, epoch, meter_loss.value()[0], acc.value()[0]))\n",
    " \n",
    "    return acc.value()[0], meter_loss.value()[0]\n",
    "\n",
    "num_epochs = 100\n",
    "evaluate_every_epoch = 1\n",
    "for e in range(num_epochs):\n",
    "    run_epoch(trLD, model, criterion, e, True, optimizer)\n",
    "    if e % evaluate_every_epoch == 0:\n",
    "        run_epoch(valLD, model, criterion, e, False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your results on Kaggle\n",
    "\n",
    "### Train a better model for action recognition!\n",
    "Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves better accuracy on the action recognition validation set.\n",
    "\n",
    "\n",
    "### Testing the model and submit on Kaggle\n",
    "Testing the model on the testing set and save the results as a .csv file. \n",
    "Please submitted the results.csv file generated by predict_on_test() to Kaggle(https://www.kaggle.com/t/934b80879bd741e6ac1967195604d4d9) to see how well your network performs on the test set. \n",
    "################ 3rd To Do  (20 points, the highest 3 entries get extra 10 points) ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Use your best model to generate results on test set.\n",
    "\n",
    "# generate csv file for test set\n",
    "def predict_on_test(model, data_loader):\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    results=open('results.csv','w')\n",
    "    count=0\n",
    "    results.write('Id'+','+'Class'+'\\n')\n",
    "    for batch_idx, sample in enumerate(data_loader):\n",
    "        sequence = sample['seq']\n",
    "        input_sequence_var = Variable(sequence).type(FloatTensor)\n",
    "        scores = model(input_sequence_var)\n",
    "        _, preds = scores.data.max(1)\n",
    "        for i in range(len(preds)):\n",
    "            results.write(str(count)+','+str(preds[i])+'\\n')\n",
    "            count+=1\n",
    "    results.close()\n",
    "    return count\n",
    "\n",
    "count=predict_on_test(model, tstLD)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Results.csv to Kaggle Friendly File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ans = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = []\n",
    "for i in range(len(df_ans)):\n",
    "    ans.append(df_ans['Class'][i][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ans['Class'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ans.to_csv('result_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report the performance\n",
    "################ 4th To Do  (5 points)##################\n",
    "\n",
    "In this cell, you should write an explanation of what you did (network architecture, optimiziter, learning rate, epochs) and any visualizations or graphs that you make in the process of training and evaluating your network.\n",
    "\n",
    "Report your Kaggle Performance here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Accuracy Achieved on Kaggle - Final Model Used = Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.75400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Layers:\n",
    "##### 8 layers\n",
    "\n",
    "## Total Epochs Used:\n",
    "#### 100 epochs\n",
    "\n",
    "## Learning Rate Used:\n",
    "#### For optimzer - 1e-3\n",
    "\n",
    "## Project Layer\n",
    "#### - self.project_layer = nn.Linear(75, 200)\n",
    "#### - self.project_layer_2 = nn.Linear(200, 300)\n",
    "## Recurrent Layer\n",
    "#### - self.recurrent_layer = nn.LSTM(300, 400, batch_first = True)\n",
    "#### - self.recurrent_layer_2 = nn.LSTM(400, 500, batch_first = True)\n",
    "#### - self.recurrent_layer_3 = nn.LSTM(500, 500, batch_first = True)\n",
    "## Classify Layer\n",
    "#### - self.classify_layer = nn.Linear(500, 300)\n",
    "#### - self.classify_layer_2 = nn.Linear(300, 100)\n",
    "#### - self.classify_layer_3 = nn.Linear(100, 10)\n",
    "## Regularization function\n",
    "#### - self.regularization = nn.Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @ For my final model after many trial, I used 2 linear layers for the Project_Layer with the first Project_Layer getting the input of RNN as 75 and output of 200. I then used another Project_Layer which took the input as 100 (which was the output of the previous layer) and had an output dimentsion of 300.\n",
    "#### @ The output of this Project Layer became the input of my first Recurrent_Layer which was a LSTM layer and had an input of 300 and hidden dimension of 400. After this I used my regularization function -> dropout with a threshold value of 0.2. After first layer I had my second Recurrent_Layer with input dimension as 400 and hidden dimansion as 400. Again after this I used my regularization function -> dropout with a threshold value of 0.2.\n",
    "#### @ I added one last recurrent_layer of LSTM with input dimension of 400 and hidden dimension of 500. Followed by my regularization function -> dropout with a threshold value of 0.2.\n",
    "#### @ Lastly, I had three classify_layers which were Linear Layers and they dropped the dimension from 500 to 10 which was our num_class size. In between every layer I used my regularization function -> dropout with a threshold value of 0.2.\n",
    "#### @ Finally this output I saved in logit and returned.\n",
    "\n",
    "#### @ My final optimizer was the optim.Adam optimizer with a learning rate of 1e-3. I tried the SGD optimizer as well but got better results with Adam Optimizer. Also, many blogs online suggested that they got better results with Adam optimizer for LSTM and hence my decison.\n",
    "\n",
    "#### @ My loss function was CrossEntropyLoss() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Accuracy - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.85000000000001"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(trainModel_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Accuracy - Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(valModel_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min Loss - Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0368)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(trainModel_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min Loss - Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6480)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(valModel_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots - Accuracy and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1363d3cc0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133666278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(100), trainModel_accuracy, label='Training Data')\n",
    "plt.plot(np.arange(100), valModel_accuracy, label='Validation Data')\n",
    "plt.title('Accuracy of Models')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy %age')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x139be9b00>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFNCAYAAACuWnPfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEIIYWMSkAkhhBBC2JgEZEIIIYQQNvb/rtYQgRDYbPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131cbce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.arange(100), trainModel_loss, label='Training Data')\n",
    "plt.plot(np.arange(100), valModel_loss, label='Validation Data')\n",
    "plt.title('Loss of Models')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Loass Value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
